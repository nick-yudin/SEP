{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ§  M3câ€´: Optimized HDC Semantic Transfer â€” Teacher\n",
        "\n",
        "## Incorporates learnings from M2.5c + M2.5e\n",
        "\n",
        "| Improvement | Source | Description |\n",
        "|-------------|--------|-------------|\n",
        "| HDC K-means curation | M2.5c | Cluster-based selection beats confidence threshold |\n",
        "| Difficulty scoring | M2.5e | Distance from centroid = difficulty |\n",
        "| Sharp curriculum data | M2.5e | Provide easy + hard examples for Student |\n",
        "\n",
        "**GPU:** T4 is sufficient\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets accelerate\n",
        "!pip install -q firebase-admin\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q scikit-learn\n",
        "print(\"âœ… Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import json\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.cluster import KMeans\n",
        "import base64\n",
        "\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, db\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nðŸ§  M3câ€´ Teacher â€” HDC K-means + Curriculum\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FIREBASE CREDENTIALS - INSERT YOUR KEY HERE\n",
        "# ============================================================\n",
        "FIREBASE_CREDENTIALS = \"INSERT KEY HERE\"\n",
        "\n",
        "FIREBASE_DATABASE_URL = \"https://resonance-m3-default-rtdb.europe-west1.firebasedatabase.app\"\n",
        "\n",
        "if not firebase_admin._apps:\n",
        "    cred = credentials.Certificate(FIREBASE_CREDENTIALS)\n",
        "    firebase_admin.initialize_app(cred, {'databaseURL': FIREBASE_DATABASE_URL})\n",
        "print(\"âœ… Firebase initialized\")"
      ],
      "metadata": {
        "id": "firebase"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HDC Encoder with Learned Projection"
      ],
      "metadata": {
        "id": "hdc_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LearnedHDCEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    HDC Encoder with learned projection.\n",
        "    Trained with contrastive loss to preserve semantic similarity.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, hdc_dim=10000, semantic_dim=384):\n",
        "        super().__init__()\n",
        "        self.hdc_dim = hdc_dim\n",
        "        self.semantic_dim = semantic_dim\n",
        "        \n",
        "        self.semantic_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        \n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(semantic_dim, hdc_dim),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        nn.init.xavier_uniform_(self.projection[0].weight)\n",
        "        \n",
        "        print(f\"âœ… HDC Encoder: {semantic_dim}d â†’ {hdc_dim}d\")\n",
        "    \n",
        "    def get_semantic_embeddings(self, texts):\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "        with torch.no_grad():\n",
        "            return self.semantic_encoder.encode(\n",
        "                texts, convert_to_tensor=True, show_progress_bar=False\n",
        "            )\n",
        "    \n",
        "    def forward(self, semantic_embeddings):\n",
        "        return self.projection(semantic_embeddings)\n",
        "    \n",
        "    def encode(self, texts, quantize=True):\n",
        "        semantic = self.get_semantic_embeddings(texts)\n",
        "        if semantic.device != next(self.projection.parameters()).device:\n",
        "            semantic = semantic.to(next(self.projection.parameters()).device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            hdc_vecs = self.forward(semantic)\n",
        "        \n",
        "        if quantize:\n",
        "            hdc_np = hdc_vecs.cpu().numpy()\n",
        "            threshold = 0.33\n",
        "            return np.where(hdc_np > threshold, 1,\n",
        "                           np.where(hdc_np < -threshold, -1, 0)).astype(np.int8)\n",
        "        return hdc_vecs.cpu().numpy()\n",
        "    \n",
        "    def encode_batch(self, texts, batch_size=64, quantize=True):\n",
        "        \"\"\"Encode large list of texts in batches.\"\"\"\n",
        "        all_vecs = []\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Encoding HDC\"):\n",
        "            batch = list(texts[i:i+batch_size])\n",
        "            vecs = self.encode(batch, quantize=quantize)\n",
        "            all_vecs.append(vecs)\n",
        "        return np.vstack(all_vecs)\n",
        "\n",
        "HDC_DIM = 10000\n",
        "hdc_encoder = LearnedHDCEncoder(hdc_dim=HDC_DIM).to(device)"
      ],
      "metadata": {
        "id": "hdc_encoder"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_hdc_projection(encoder, texts, labels, epochs=10, batch_size=64):\n",
        "    \"\"\"Train projection with contrastive loss.\"\"\"\n",
        "    print(\"\\nðŸ”§ Training HDC Projection (contrastive)...\")\n",
        "    \n",
        "    # Get semantic embeddings\n",
        "    all_semantics = []\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"   Semantic encoding\"):\n",
        "        batch = list(texts[i:i+batch_size])\n",
        "        emb = encoder.get_semantic_embeddings(batch)\n",
        "        all_semantics.append(emb)\n",
        "    all_semantics = torch.cat(all_semantics, dim=0).to(device)\n",
        "    all_labels = torch.tensor(labels).to(device)\n",
        "    \n",
        "    optimizer = optim.Adam(encoder.projection.parameters(), lr=1e-3)\n",
        "    encoder.projection.train()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        n_batches = 0\n",
        "        perm = torch.randperm(len(all_semantics))\n",
        "        \n",
        "        for i in range(0, len(all_semantics), batch_size):\n",
        "            idx = perm[i:i+batch_size]\n",
        "            batch_sem = all_semantics[idx]\n",
        "            batch_labels = all_labels[idx]\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            hdc_vecs = encoder.projection(batch_sem)\n",
        "            hdc_norm = F.normalize(hdc_vecs, p=2, dim=1)\n",
        "            \n",
        "            sim_matrix = hdc_norm @ hdc_norm.T\n",
        "            label_mask = (batch_labels.unsqueeze(0) == batch_labels.unsqueeze(1)).float()\n",
        "            \n",
        "            margin = 0.5\n",
        "            pos_loss = ((1 - sim_matrix) * label_mask).sum() / (label_mask.sum() + 1e-8)\n",
        "            neg_loss = (F.relu(sim_matrix - margin) * (1 - label_mask)).sum() / ((1 - label_mask).sum() + 1e-8)\n",
        "            \n",
        "            loss = pos_loss + neg_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            n_batches += 1\n",
        "        \n",
        "        if (epoch + 1) % 2 == 0:\n",
        "            print(f\"   Epoch {epoch+1}/{epochs} | Loss: {total_loss/n_batches:.4f}\")\n",
        "    \n",
        "    encoder.projection.eval()\n",
        "    print(\"âœ… Projection trained!\")\n",
        "    return encoder"
      ],
      "metadata": {
        "id": "train_projection"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data and Train Teacher"
      ],
      "metadata": {
        "id": "data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME, num_labels=2\n",
        ").to(device)\n",
        "\n",
        "print(f\"âœ… Teacher: {MODEL_NAME}\")"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading SST-2...\")\n",
        "dataset = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "TRAIN_SIZE = 3000\n",
        "TEST_SIZE = 500\n",
        "\n",
        "train_texts = dataset['train']['sentence'][:TRAIN_SIZE]\n",
        "train_labels = dataset['train']['label'][:TRAIN_SIZE]\n",
        "test_texts = dataset['validation']['sentence'][:TEST_SIZE]\n",
        "test_labels = dataset['validation']['label'][:TEST_SIZE]\n",
        "\n",
        "print(f\"âœ… Train: {len(train_texts)}, Test: {len(test_texts)}\")"
      ],
      "metadata": {
        "id": "load_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.encodings = tokenizer(\n",
        "            list(texts), truncation=True, padding='max_length',\n",
        "            max_length=max_length, return_tensors='pt'\n",
        "        )\n",
        "        self.labels = torch.tensor(list(labels))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.encodings['input_ids'][idx],\n",
        "            'attention_mask': self.encodings['attention_mask'][idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
        "test_dataset = SentimentDataset(test_texts, test_labels, tokenizer)"
      ],
      "metadata": {
        "id": "create_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions_with_confidence(model, texts, tokenizer, batch_size=32):\n",
        "    model.eval()\n",
        "    predictions, confidences = [], []\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting\"):\n",
        "        batch_texts = list(texts[i:i+batch_size])\n",
        "        inputs = tokenizer(\n",
        "            batch_texts, truncation=True, padding=True,\n",
        "            max_length=128, return_tensors='pt'\n",
        "        ).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            probs = F.softmax(outputs.logits, dim=1)\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "            confs = probs.max(dim=1).values\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            confidences.extend(confs.cpu().numpy())\n",
        "    return np.array(predictions), np.array(confidences)\n",
        "\n",
        "print(\"ðŸ“Š Teacher BEFORE training...\")\n",
        "preds_before, _ = get_predictions_with_confidence(model, test_texts, tokenizer)\n",
        "acc_before = accuracy_score(test_labels, preds_before)\n",
        "print(f\"âœ… Accuracy BEFORE: {acc_before:.1%}\")"
      ],
      "metadata": {
        "id": "before_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./teacher_output\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=100,\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model, args=training_args,\n",
        "    train_dataset=train_dataset, eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "print(\"\\nðŸ‹ï¸ Training Teacher...\")\n",
        "trainer.train()\n",
        "print(\"âœ… Done!\")"
      ],
      "metadata": {
        "id": "train_teacher"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ“Š Teacher AFTER training...\")\n",
        "preds_after, _ = get_predictions_with_confidence(model, test_texts, tokenizer)\n",
        "acc_after = accuracy_score(test_labels, preds_after)\n",
        "print(f\"âœ… Accuracy AFTER: {acc_after:.1%} (+{acc_after - acc_before:.1%})\")"
      ],
      "metadata": {
        "id": "after_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train HDC Projection"
      ],
      "metadata": {
        "id": "hdc_train_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hdc_encoder = train_hdc_projection(\n",
        "    hdc_encoder, train_texts, train_labels, epochs=10, batch_size=64\n",
        ")"
      ],
      "metadata": {
        "id": "train_hdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HDC K-means Curation (from M2.5c)\n",
        "\n",
        "Instead of confidence threshold, use K-means clustering:\n",
        "- Cluster all HDC vectors\n",
        "- Select nearest to centroid (canonical examples)"
      ],
      "metadata": {
        "id": "curation_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ¯ HDC K-MEANS CURATION (M2.5c method)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get teacher predictions (we only want correct ones)\n",
        "train_preds, train_confs = get_predictions_with_confidence(model, train_texts, tokenizer)\n",
        "correct_mask = (train_preds == np.array(train_labels))\n",
        "print(f\"\\nâœ… Correct predictions: {correct_mask.sum()}/{len(train_texts)}\")\n",
        "\n",
        "# Filter to correct predictions only\n",
        "correct_indices = np.where(correct_mask)[0]\n",
        "correct_texts = [train_texts[i] for i in correct_indices]\n",
        "correct_labels = [train_labels[i] for i in correct_indices]\n",
        "\n",
        "# Encode all correct texts to HDC\n",
        "print(\"\\nðŸ”„ Encoding to HDC space...\")\n",
        "all_hdc = hdc_encoder.encode_batch(correct_texts, batch_size=64, quantize=False)  # Float for K-means\n",
        "print(f\"   HDC vectors shape: {all_hdc.shape}\")"
      ],
      "metadata": {
        "id": "encode_all"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-means clustering\n",
        "N_CLUSTERS = 500  # Half will be easy, half will be hard\n",
        "\n",
        "print(f\"\\nðŸ”® K-means clustering (k={N_CLUSTERS})...\")\n",
        "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init=10)\n",
        "cluster_labels = kmeans.fit_predict(all_hdc)\n",
        "print(f\"âœ… Clustering complete\")"
      ],
      "metadata": {
        "id": "kmeans"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For each cluster, compute distance from centroid for all members\n",
        "# This gives us difficulty scores (closer = easier, farther = harder)\n",
        "\n",
        "print(\"\\nðŸ“Š Computing difficulty scores...\")\n",
        "\n",
        "difficulties = np.zeros(len(all_hdc))\n",
        "for i in range(len(all_hdc)):\n",
        "    cluster_id = cluster_labels[i]\n",
        "    centroid = kmeans.cluster_centers_[cluster_id]\n",
        "    difficulties[i] = np.linalg.norm(all_hdc[i] - centroid)\n",
        "\n",
        "print(f\"   Difficulty range: {difficulties.min():.2f} - {difficulties.max():.2f}\")\n",
        "print(f\"   Difficulty mean: {difficulties.mean():.2f}\")"
      ],
      "metadata": {
        "id": "difficulty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select examples for curriculum (from M2.5e: sharp curriculum)\n",
        "# Easy: nearest to centroids (low difficulty)\n",
        "# Hard: farthest from centroids (high difficulty)\n",
        "\n",
        "N_EASY = 500   # Centroid-near examples\n",
        "N_HARD = 500   # Boundary examples\n",
        "\n",
        "print(f\"\\nðŸŽ¯ Selecting curriculum examples...\")\n",
        "print(f\"   Easy (centroid-near): {N_EASY}\")\n",
        "print(f\"   Hard (boundary): {N_HARD}\")\n",
        "\n",
        "# Sort by difficulty\n",
        "sorted_indices = np.argsort(difficulties)\n",
        "\n",
        "# Easy = lowest difficulty (first N_EASY)\n",
        "easy_indices = sorted_indices[:N_EASY]\n",
        "\n",
        "# Hard = highest difficulty (last N_HARD)\n",
        "hard_indices = sorted_indices[-N_HARD:]\n",
        "\n",
        "print(f\"\\n   Easy difficulty range: {difficulties[easy_indices].min():.2f} - {difficulties[easy_indices].max():.2f}\")\n",
        "print(f\"   Hard difficulty range: {difficulties[hard_indices].min():.2f} - {difficulties[hard_indices].max():.2f}\")"
      ],
      "metadata": {
        "id": "select_curriculum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create HDC knowledge packet with difficulty scores\n",
        "print(\"\\nðŸ“¦ Creating HDC Knowledge Packet with curriculum data...\")\n",
        "\n",
        "def quantize_to_ternary(vec):\n",
        "    threshold = 0.33\n",
        "    return np.where(vec > threshold, 1, np.where(vec < -threshold, -1, 0)).astype(np.int8)\n",
        "\n",
        "hdc_knowledge = []\n",
        "\n",
        "# Add easy examples\n",
        "for idx in tqdm(easy_indices, desc=\"Easy examples\"):\n",
        "    hdc_vec = quantize_to_ternary(all_hdc[idx])\n",
        "    hdc_knowledge.append({\n",
        "        'hdc_vector': hdc_vec.tolist(),\n",
        "        'label': int(correct_labels[idx]),\n",
        "        'difficulty': float(difficulties[idx]),\n",
        "        'curriculum': 'easy'\n",
        "    })\n",
        "\n",
        "# Add hard examples\n",
        "for idx in tqdm(hard_indices, desc=\"Hard examples\"):\n",
        "    hdc_vec = quantize_to_ternary(all_hdc[idx])\n",
        "    hdc_knowledge.append({\n",
        "        'hdc_vector': hdc_vec.tolist(),\n",
        "        'label': int(correct_labels[idx]),\n",
        "        'difficulty': float(difficulties[idx]),\n",
        "        'curriculum': 'hard'\n",
        "    })\n",
        "\n",
        "print(f\"\\nâœ… Total examples: {len(hdc_knowledge)}\")\n",
        "print(f\"   Easy: {sum(1 for x in hdc_knowledge if x['curriculum'] == 'easy')}\")\n",
        "print(f\"   Hard: {sum(1 for x in hdc_knowledge if x['curriculum'] == 'hard')}\")"
      ],
      "metadata": {
        "id": "create_packet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check label balance\n",
        "easy_labels = [x['label'] for x in hdc_knowledge if x['curriculum'] == 'easy']\n",
        "hard_labels = [x['label'] for x in hdc_knowledge if x['curriculum'] == 'hard']\n",
        "\n",
        "print(f\"\\nðŸ“Š Label balance:\")\n",
        "print(f\"   Easy - Pos: {sum(easy_labels)}, Neg: {len(easy_labels) - sum(easy_labels)}\")\n",
        "print(f\"   Hard - Pos: {sum(hard_labels)}, Neg: {len(hard_labels) - sum(hard_labels)}\")"
      ],
      "metadata": {
        "id": "check_balance"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compress for upload\n",
        "def compress_hdc_packet(knowledge):\n",
        "    compressed = []\n",
        "    for ex in knowledge:\n",
        "        vec = np.array(ex['hdc_vector'], dtype=np.int8)\n",
        "        mapped = (vec + 1).astype(np.uint8)\n",
        "        packed = np.zeros(len(vec) // 4, dtype=np.uint8)\n",
        "        for j in range(4):\n",
        "            packed |= (mapped[j::4] << (j * 2))\n",
        "        compressed.append({\n",
        "            'hdc_packed': base64.b64encode(packed.tobytes()).decode('ascii'),\n",
        "            'label': ex['label'],\n",
        "            'difficulty': ex['difficulty'],\n",
        "            'curriculum': ex['curriculum']\n",
        "        })\n",
        "    return compressed\n",
        "\n",
        "compressed_knowledge = compress_hdc_packet(hdc_knowledge)\n",
        "\n",
        "raw_size = len(hdc_knowledge) * HDC_DIM\n",
        "compressed_size = sum(len(ex['hdc_packed']) for ex in compressed_knowledge)\n",
        "\n",
        "print(f\"\\nðŸ“¦ Compression:\")\n",
        "print(f\"   Raw: {raw_size / 1024:.1f} KB\")\n",
        "print(f\"   Compressed: {compressed_size / 1024:.1f} KB\")\n",
        "print(f\"   Ratio: {raw_size / compressed_size:.1f}Ã—\")"
      ],
      "metadata": {
        "id": "compress"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save projection weights\n",
        "projection_weights = {\n",
        "    'weight': hdc_encoder.projection[0].weight.cpu().detach().numpy().tolist(),\n",
        "    'bias': hdc_encoder.projection[0].bias.cpu().detach().numpy().tolist(),\n",
        "}"
      ],
      "metadata": {
        "id": "save_projection"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload to Firebase"
      ],
      "metadata": {
        "id": "upload_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸ“¤ Uploading to Firebase...\")\n",
        "\n",
        "knowledge_packet = {\n",
        "    'experiment': 'M3c_triple_prime_v2',\n",
        "    'version': 'curriculum_optimized',\n",
        "    'description': 'HDC K-means curation + Sharp curriculum (M2.5c + M2.5e)',\n",
        "    'teacher_model': MODEL_NAME,\n",
        "    'teacher_accuracy_before': float(acc_before),\n",
        "    'teacher_accuracy_after': float(acc_after),\n",
        "    'teacher_improvement': float(acc_after - acc_before),\n",
        "    'hdc_dim': HDC_DIM,\n",
        "    'projection_type': 'learned_contrastive',\n",
        "    'projection_weights': projection_weights,\n",
        "    'curation_method': 'kmeans_clustering',\n",
        "    'n_clusters': N_CLUSTERS,\n",
        "    'num_examples': len(compressed_knowledge),\n",
        "    'num_easy': N_EASY,\n",
        "    'num_hard': N_HARD,\n",
        "    'curriculum_strategy': 'sharp',\n",
        "    'examples': compressed_knowledge,\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'insights_from': ['M2.5c (HDC curation)', 'M2.5e (curriculum learning)']\n",
        "}\n",
        "\n",
        "ref = db.reference('sep_m3c_hdc_v3/knowledge_packet')\n",
        "ref.set(knowledge_packet)\n",
        "\n",
        "ref = db.reference('sep_m3c_hdc_v3/status')\n",
        "ref.set({\n",
        "    'teacher_ready': True,\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'hdc_dim': HDC_DIM,\n",
        "    'num_examples': len(compressed_knowledge),\n",
        "    'curriculum': 'sharp (easyâ†’hard)',\n",
        "    'teacher_accuracy': float(acc_after)\n",
        "})\n",
        "\n",
        "print(f\"\\nâœ… Uploaded!\")\n",
        "print(f\"\\nðŸ“‹ Summary:\")\n",
        "print(f\"   Teacher: {acc_before:.1%} â†’ {acc_after:.1%}\")\n",
        "print(f\"   HDC dim: {HDC_DIM}\")\n",
        "print(f\"   Curation: K-means ({N_CLUSTERS} clusters)\")\n",
        "print(f\"   Curriculum: Sharp (easyâ†’hard)\")\n",
        "print(f\"   Examples: {len(compressed_knowledge)} ({N_EASY} easy + {N_HARD} hard)\")"
      ],
      "metadata": {
        "id": "upload"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results\n",
        "results = {\n",
        "    'phase': 'M3c_triple_prime_v2',\n",
        "    'node': 'teacher',\n",
        "    'model': MODEL_NAME,\n",
        "    'accuracy_before': float(acc_before),\n",
        "    'accuracy_after': float(acc_after),\n",
        "    'hdc_dim': HDC_DIM,\n",
        "    'curation': 'kmeans',\n",
        "    'n_clusters': N_CLUSTERS,\n",
        "    'curriculum': 'sharp',\n",
        "    'n_easy': N_EASY,\n",
        "    'n_hard': N_HARD,\n",
        "    'total_examples': len(compressed_knowledge),\n",
        "    'optimizations': [\n",
        "        'M2.5c: HDC K-means curation',\n",
        "        'M2.5e: Sharp curriculum (easyâ†’hard)',\n",
        "        'M2.5e: Difficulty = distance from centroid',\n",
        "        'Learned projection (contrastive)'\n",
        "    ],\n",
        "    'timestamp': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "with open('m3c_v3_teacher_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ“ TEACHER COMPLETE â€” Run Student (L4) now!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "save_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('m3c_v3_teacher_results.json')"
      ],
      "metadata": {
        "id": "download"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
