{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“š M3câ€´: Optimized HDC Semantic Transfer â€” Student\n",
        "\n",
        "## Key insights from M2.5e applied:\n",
        "\n",
        "| M2.5e Finding | Implementation |\n",
        "|---------------|----------------|\n",
        "| **Sharp curriculum: easy â†’ hard** | Train on easy first, then add hard |\n",
        "| **Constant LR (NO decay!)** | Fixed learning rate throughout |\n",
        "| **Distance from centroid = difficulty** | Use difficulty scores from Teacher |\n",
        "| **+8.1% improvement potential** | Target: 59% â†’ 70%+ transfer efficiency |\n",
        "\n",
        "**GPU:** L4 recommended\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install -q firebase-admin\n",
        "!pip install -q sentence-transformers\n",
        "print(\"âœ… Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import json\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, db\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nðŸ“š M3câ€´ Student â€” Sharp Curriculum + Constant LR\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FIREBASE CREDENTIALS - INSERT YOUR KEY HERE\n",
        "# ============================================================\n",
        "FIREBASE_CREDENTIALS = \"INSERT KEY HERE\"\n",
        "\n",
        "FIREBASE_DATABASE_URL = \"https://resonance-m3-default-rtdb.europe-west1.firebasedatabase.app\"\n",
        "\n",
        "if not firebase_admin._apps:\n",
        "    cred = credentials.Certificate(FIREBASE_CREDENTIALS)\n",
        "    firebase_admin.initialize_app(cred, {'databaseURL': FIREBASE_DATABASE_URL})\n",
        "print(\"âœ… Firebase initialized\")"
      ],
      "metadata": {
        "id": "firebase"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Knowledge Packet"
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ“¡ Checking for Teacher...\")\n",
        "\n",
        "ref = db.reference('sep_m3c_hdc_v3/status')\n",
        "status = ref.get()\n",
        "\n",
        "if status and status.get('teacher_ready', False):\n",
        "    print(f\"âœ… Teacher ready!\")\n",
        "    print(f\"   HDC dim: {status.get('hdc_dim')}\")\n",
        "    print(f\"   Examples: {status.get('num_examples')}\")\n",
        "    print(f\"   Curriculum: {status.get('curriculum')}\")\n",
        "    print(f\"   Teacher accuracy: {status.get('teacher_accuracy', 0):.1%}\")\n",
        "else:\n",
        "    print(\"âš ï¸ Teacher not ready!\")\n",
        "    raise Exception(\"Run Teacher first\")"
      ],
      "metadata": {
        "id": "check_teacher"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸ“¥ Downloading knowledge packet...\")\n",
        "\n",
        "ref = db.reference('sep_m3c_hdc_v3/knowledge_packet')\n",
        "knowledge_packet = ref.get()\n",
        "\n",
        "HDC_DIM = knowledge_packet['hdc_dim']\n",
        "projection_weights = knowledge_packet['projection_weights']\n",
        "teacher_acc_before = knowledge_packet['teacher_accuracy_before']\n",
        "teacher_acc_after = knowledge_packet['teacher_accuracy_after']\n",
        "\n",
        "print(f\"\\nðŸ“‹ Knowledge Packet:\")\n",
        "print(f\"   Version: {knowledge_packet.get('version')}\")\n",
        "print(f\"   HDC dim: {HDC_DIM}\")\n",
        "print(f\"   Curation: {knowledge_packet.get('curation_method')}\")\n",
        "print(f\"   Curriculum: {knowledge_packet.get('curriculum_strategy')}\")\n",
        "print(f\"   Easy: {knowledge_packet.get('num_easy')}, Hard: {knowledge_packet.get('num_hard')}\")\n",
        "print(f\"   Teacher: {teacher_acc_before:.1%} â†’ {teacher_acc_after:.1%}\")"
      ],
      "metadata": {
        "id": "download_packet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decompress_hdc_packet(compressed_examples, hdc_dim):\n",
        "    examples = []\n",
        "    for ex in tqdm(compressed_examples, desc=\"Decompressing\"):\n",
        "        packed = np.frombuffer(base64.b64decode(ex['hdc_packed']), dtype=np.uint8)\n",
        "        unpacked = np.zeros(hdc_dim, dtype=np.int8)\n",
        "        for j in range(4):\n",
        "            unpacked[j::4] = (packed >> (j * 2)) & 0b11\n",
        "        hdc_vec = unpacked.astype(np.int8) - 1\n",
        "        examples.append({\n",
        "            'hdc_vector': hdc_vec,\n",
        "            'label': ex['label'],\n",
        "            'difficulty': ex['difficulty'],\n",
        "            'curriculum': ex['curriculum']\n",
        "        })\n",
        "    return examples\n",
        "\n",
        "hdc_examples = decompress_hdc_packet(knowledge_packet['examples'], HDC_DIM)\n",
        "\n",
        "# Separate easy and hard\n",
        "easy_examples = [ex for ex in hdc_examples if ex['curriculum'] == 'easy']\n",
        "hard_examples = [ex for ex in hdc_examples if ex['curriculum'] == 'hard']\n",
        "\n",
        "print(f\"\\nâœ… Decompressed: {len(easy_examples)} easy + {len(hard_examples)} hard\")"
      ],
      "metadata": {
        "id": "decompress"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HDC Encoder (with Teacher's projection)"
      ],
      "metadata": {
        "id": "encoder_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LearnedHDCEncoder(nn.Module):\n",
        "    def __init__(self, hdc_dim=10000, semantic_dim=384):\n",
        "        super().__init__()\n",
        "        self.hdc_dim = hdc_dim\n",
        "        self.semantic_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(semantic_dim, hdc_dim),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "    \n",
        "    def load_projection_weights(self, weights_dict):\n",
        "        self.projection[0].weight.data = torch.tensor(weights_dict['weight'], dtype=torch.float32)\n",
        "        self.projection[0].bias.data = torch.tensor(weights_dict['bias'], dtype=torch.float32)\n",
        "        print(\"âœ… Loaded Teacher's projection\")\n",
        "    \n",
        "    def encode(self, texts, quantize=True):\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "        with torch.no_grad():\n",
        "            semantic = self.semantic_encoder.encode(texts, convert_to_tensor=True, show_progress_bar=False)\n",
        "            if semantic.device != next(self.projection.parameters()).device:\n",
        "                semantic = semantic.to(next(self.projection.parameters()).device)\n",
        "            hdc_vecs = self.projection(semantic)\n",
        "        \n",
        "        if quantize:\n",
        "            hdc_np = hdc_vecs.cpu().numpy()\n",
        "            threshold = 0.33\n",
        "            return np.where(hdc_np > threshold, 1, np.where(hdc_np < -threshold, -1, 0)).astype(np.int8)\n",
        "        return hdc_vecs.cpu().numpy()\n",
        "\n",
        "hdc_encoder = LearnedHDCEncoder(hdc_dim=HDC_DIM).to(device)\n",
        "hdc_encoder.load_projection_weights(projection_weights)\n",
        "hdc_encoder.eval()"
      ],
      "metadata": {
        "id": "hdc_encoder"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improved Student Model"
      ],
      "metadata": {
        "id": "student_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.BatchNorm1d(dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.BatchNorm1d(dim),\n",
        "        )\n",
        "        self.activation = nn.GELU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.activation(x + self.block(x)))\n",
        "\n",
        "\n",
        "class ImprovedHDCClassifier(nn.Module):\n",
        "    def __init__(self, hdc_dim, hidden_dim=1024, num_classes=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Sequential(\n",
        "            nn.Linear(hdc_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            ResidualBlock(hidden_dim, dropout),\n",
        "            ResidualBlock(hidden_dim, dropout),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.BatchNorm1d(hidden_dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, num_classes)\n",
        "        )\n",
        "        self.num_params = sum(p.numel() for p in self.parameters())\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.res_blocks(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "student = ImprovedHDCClassifier(hdc_dim=HDC_DIM, hidden_dim=1024, dropout=0.1).to(device)\n",
        "print(f\"\\nðŸ“š Student: {student.num_params:,} parameters\")"
      ],
      "metadata": {
        "id": "student_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Test Data"
      ],
      "metadata": {
        "id": "test_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading test data...\")\n",
        "dataset = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "TEST_SIZE = 500\n",
        "test_texts = dataset['validation']['sentence'][:TEST_SIZE]\n",
        "test_labels = dataset['validation']['label'][:TEST_SIZE]\n",
        "\n",
        "# Encode to HDC\n",
        "print(\"\\nðŸ”„ Encoding test texts...\")\n",
        "test_hdc = []\n",
        "for i in tqdm(range(0, len(test_texts), 64), desc=\"Encoding\"):\n",
        "    batch = list(test_texts[i:i+64])\n",
        "    vecs = hdc_encoder.encode(batch, quantize=True)\n",
        "    test_hdc.extend(vecs)\n",
        "test_hdc = np.array(test_hdc)\n",
        "\n",
        "print(f\"âœ… Test: {test_hdc.shape}\")"
      ],
      "metadata": {
        "id": "prepare_test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HDCDataset(Dataset):\n",
        "    def __init__(self, hdc_vectors, labels):\n",
        "        self.hdc = torch.tensor(hdc_vectors, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.hdc[idx], self.labels[idx]\n",
        "\n",
        "test_dataset = HDCDataset(test_hdc, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "test_loader"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for hdc, labels in dataloader:\n",
        "            hdc = hdc.to(device)\n",
        "            outputs = model(hdc)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "    return accuracy_score(all_labels, all_preds)\n",
        "\n",
        "print(\"ðŸ“Š Student BEFORE training...\")\n",
        "acc_before = evaluate(student, test_loader)\n",
        "print(f\"âœ… Accuracy BEFORE: {acc_before:.1%}\")"
      ],
      "metadata": {
        "id": "before_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sharp Curriculum Training (M2.5e)\n",
        "\n",
        "**Key insights applied:**\n",
        "1. **Sharp curriculum:** Easy examples first, then hard\n",
        "2. **Constant LR:** NO learning rate decay!\n",
        "3. **Phase transitions:** Clear boundaries between easy/hard"
      ],
      "metadata": {
        "id": "train_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ§  SHARP CURRICULUM TRAINING (M2.5e method)\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nðŸ“š Strategy:\")\n",
        "print(\"   Phase 1 (epochs 1-15):  EASY examples only\")\n",
        "print(\"   Phase 2 (epochs 16-35): EASY + HARD examples\")\n",
        "print(\"   Phase 3 (epochs 36-50): All examples\")\n",
        "print(\"\\nâš ï¸  CONSTANT LR = 5e-4 (no decay!)\")"
      ],
      "metadata": {
        "id": "train_intro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare curriculum datasets\n",
        "easy_hdc = np.array([ex['hdc_vector'] for ex in easy_examples])\n",
        "easy_labels = np.array([ex['label'] for ex in easy_examples])\n",
        "hard_hdc = np.array([ex['hdc_vector'] for ex in hard_examples])\n",
        "hard_labels = np.array([ex['label'] for ex in hard_examples])\n",
        "\n",
        "# Combined dataset\n",
        "all_hdc = np.vstack([easy_hdc, hard_hdc])\n",
        "all_labels = np.concatenate([easy_labels, hard_labels])\n",
        "\n",
        "print(f\"\\nðŸ“Š Curriculum data:\")\n",
        "print(f\"   Easy: {len(easy_hdc)}\")\n",
        "print(f\"   Hard: {len(hard_hdc)}\")\n",
        "print(f\"   Total: {len(all_hdc)}\")"
      ],
      "metadata": {
        "id": "prepare_curriculum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training configuration\n",
        "NUM_EPOCHS = 50\n",
        "PHASE1_END = 15   # Easy only\n",
        "PHASE2_END = 35   # Easy + Hard\n",
        "# Phase 3: All (same as phase 2 in our case)\n",
        "\n",
        "# âš ï¸ CONSTANT LR - Key insight from M2.5e!\n",
        "LEARNING_RATE = 5e-4\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = optim.AdamW(student.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
        "# NO scheduler! Constant LR preserves adaptability (M2.5e)\n",
        "\n",
        "history = {'train_loss': [], 'train_acc': [], 'test_acc': [], 'phase': []}\n",
        "best_test_acc = 0\n",
        "best_state = None"
      ],
      "metadata": {
        "id": "training_config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Determine which data to use based on curriculum phase\n",
        "    if epoch < PHASE1_END:\n",
        "        # Phase 1: Easy only\n",
        "        phase = 1\n",
        "        train_data = HDCDataset(easy_hdc, easy_labels)\n",
        "    else:\n",
        "        # Phase 2 & 3: Easy + Hard\n",
        "        phase = 2 if epoch < PHASE2_END else 3\n",
        "        train_data = HDCDataset(all_hdc, all_labels)\n",
        "    \n",
        "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True, drop_last=True)\n",
        "    \n",
        "    # Training\n",
        "    student.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for hdc, labels in train_loader:\n",
        "        hdc = hdc.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = student(hdc)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(student.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    \n",
        "    train_loss = total_loss / len(train_loader)\n",
        "    train_acc = correct / total\n",
        "    test_acc = evaluate(student, test_loader)\n",
        "    \n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['test_acc'].append(test_acc)\n",
        "    history['phase'].append(phase)\n",
        "    \n",
        "    if test_acc > best_test_acc:\n",
        "        best_test_acc = test_acc\n",
        "        best_state = student.state_dict().copy()\n",
        "    \n",
        "    # Log phase transitions and regular progress\n",
        "    if epoch == 0 or epoch == PHASE1_END or epoch == PHASE2_END or (epoch + 1) % 10 == 0:\n",
        "        phase_str = f\"Phase {phase}\"\n",
        "        if epoch == PHASE1_END:\n",
        "            phase_str = \"â†’ Phase 2 (adding HARD)\"\n",
        "        elif epoch == PHASE2_END:\n",
        "            phase_str = \"â†’ Phase 3 (all data)\"\n",
        "        \n",
        "        data_size = len(easy_hdc) if phase == 1 else len(all_hdc)\n",
        "        print(f\"Epoch {epoch+1:2d}/{NUM_EPOCHS} | {phase_str:25} | \"\n",
        "              f\"Data: {data_size:4d} | \"\n",
        "              f\"Loss: {train_loss:.4f} | \"\n",
        "              f\"Test: {test_acc:.1%} | \"\n",
        "              f\"Best: {best_test_acc:.1%}\")\n",
        "\n",
        "# Load best model\n",
        "student.load_state_dict(best_state)\n",
        "print(f\"\\nâœ… Training complete! Best: {best_test_acc:.1%}\")"
      ],
      "metadata": {
        "id": "train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation\n",
        "acc_after = evaluate(student, test_loader)\n",
        "print(f\"\\nðŸ“Š Final accuracy: {acc_after:.1%}\")"
      ],
      "metadata": {
        "id": "final_eval"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results Analysis"
      ],
      "metadata": {
        "id": "results_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student_improvement = acc_after - acc_before\n",
        "teacher_improvement = teacher_acc_after - teacher_acc_before\n",
        "transfer_efficiency = (student_improvement / teacher_improvement) * 100 if teacher_improvement > 0 else 0\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š RESULTS: CURRICULUM-OPTIMIZED HDC TRANSFER\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nðŸŽ“ TEACHER:\")\n",
        "print(f\"   {teacher_acc_before:.1%} â†’ {teacher_acc_after:.1%} (+{teacher_improvement:.1%})\")\n",
        "\n",
        "print(f\"\\nðŸ“š STUDENT (HDC only, curriculum trained):\")\n",
        "print(f\"   {acc_before:.1%} â†’ {acc_after:.1%} (+{student_improvement:.1%})\")\n",
        "\n",
        "print(f\"\\nðŸ”„ TRANSFER EFFICIENCY: {transfer_efficiency:.1f}%\")\n",
        "\n",
        "print(f\"\\nðŸ“ˆ COMPARISON:\")\n",
        "print(f\"   M3câ€³ (random, no curriculum):     59.2%\")\n",
        "print(f\"   M3câ€´ (curriculum + constant LR): {transfer_efficiency:.1f}%\")\n",
        "print(f\"   Improvement: +{transfer_efficiency - 59.2:.1f}%\")"
      ],
      "metadata": {
        "id": "analyze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verdict\n",
        "if transfer_efficiency >= 80:\n",
        "    verdict = \"EXCELLENT\"\n",
        "    emoji = \"ðŸŽ‰\"\n",
        "elif transfer_efficiency >= 70:\n",
        "    verdict = \"VERY GOOD\"\n",
        "    emoji = \"ðŸŒŸ\"\n",
        "elif transfer_efficiency >= 65:\n",
        "    verdict = \"GOOD\"\n",
        "    emoji = \"âœ…\"\n",
        "else:\n",
        "    verdict = \"IMPROVED\"\n",
        "    emoji = \"ðŸ“ˆ\"\n",
        "\n",
        "print(f\"\\n{emoji} VERDICT: {verdict}\")\n",
        "print(f\"\\n   Curriculum learning applied: âœ…\")\n",
        "print(f\"   Constant LR (no decay): âœ…\")\n",
        "print(f\"   HDC K-means curation: âœ…\")\n",
        "print(f\"   Text seen by Student: ZERO\")"
      ],
      "metadata": {
        "id": "verdict"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Learning curve with phase markers\n",
        "ax = axes[0]\n",
        "ax.plot(history['test_acc'], label='Test Accuracy', color='orange', linewidth=2)\n",
        "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Random')\n",
        "ax.axvline(x=PHASE1_END, color='red', linestyle=':', alpha=0.7, label='Phase 2 (add hard)')\n",
        "ax.axvline(x=PHASE2_END, color='purple', linestyle=':', alpha=0.7, label='Phase 3')\n",
        "ax.fill_between(range(PHASE1_END), 0, 1, alpha=0.1, color='green', label='Easy only')\n",
        "ax.fill_between(range(PHASE1_END, NUM_EPOCHS), 0, 1, alpha=0.1, color='red')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Sharp Curriculum Learning')\n",
        "ax.legend(loc='lower right')\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim(0.4, 1.0)\n",
        "\n",
        "# Comparison bars\n",
        "ax = axes[1]\n",
        "versions = ['M3câ€³\\n(baseline)', 'M3câ€´\\n(curriculum)']\n",
        "efficiencies = [59.2, transfer_efficiency]\n",
        "colors = ['lightcoral', 'lightgreen']\n",
        "bars = ax.bar(versions, efficiencies, color=colors, edgecolor='gray')\n",
        "ax.set_ylabel('Transfer Efficiency (%)')\n",
        "ax.set_title('Transfer Efficiency Comparison')\n",
        "ax.set_ylim(0, 100)\n",
        "ax.axhline(y=80, color='green', linestyle='--', alpha=0.5, label='Target: 80%')\n",
        "for bar, val in zip(bars, efficiencies):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n",
        "            f'{val:.1f}%', ha='center', fontsize=12, fontweight='bold')\n",
        "ax.legend()\n",
        "\n",
        "# Accuracy comparison\n",
        "ax = axes[2]\n",
        "models = ['Teacher\\n(text)', 'M3câ€³\\n(HDC)', 'M3câ€´\\n(curriculum)']\n",
        "accs = [teacher_acc_after, 0.734, acc_after]\n",
        "colors = ['lightblue', 'lightyellow', 'lightgreen']\n",
        "bars = ax.bar(models, accs, color=colors, edgecolor='gray')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Final Accuracy Comparison')\n",
        "ax.set_ylim(0, 1)\n",
        "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
        "for bar, val in zip(bars, accs):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "            f'{val:.1%}', ha='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('m3c_v3_student_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "visualize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results\n",
        "results = {\n",
        "    'phase': 'M3c_triple_prime_v2',\n",
        "    'experiment': 'Curriculum-Optimized HDC Semantic Transfer',\n",
        "    'node': 'student',\n",
        "    'teacher_model': knowledge_packet.get('teacher_model'),\n",
        "    'student_model': 'ImprovedHDCClassifier (ResidualBlocks)',\n",
        "    'student_params': student.num_params,\n",
        "    'hdc_dim': HDC_DIM,\n",
        "    'curation_method': 'kmeans',\n",
        "    'curriculum_strategy': 'sharp (easyâ†’hard)',\n",
        "    'constant_lr': LEARNING_RATE,\n",
        "    'lr_decay': False,\n",
        "    'num_easy': len(easy_examples),\n",
        "    'num_hard': len(hard_examples),\n",
        "    'teacher_accuracy_before': float(teacher_acc_before),\n",
        "    'teacher_accuracy_after': float(teacher_acc_after),\n",
        "    'student_accuracy_before': float(acc_before),\n",
        "    'student_accuracy_after': float(acc_after),\n",
        "    'transfer_efficiency_pct': float(transfer_efficiency),\n",
        "    'baseline_efficiency_pct': 59.2,\n",
        "    'improvement_over_baseline': float(transfer_efficiency - 59.2),\n",
        "    'verdict': verdict,\n",
        "    'insights_applied': [\n",
        "        'M2.5c: HDC K-means curation',\n",
        "        'M2.5e: Sharp curriculum (easyâ†’hard)',\n",
        "        'M2.5e: Constant LR (no decay)',\n",
        "        'M2.5e: Distance from centroid = difficulty'\n",
        "    ],\n",
        "    'timestamp': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "with open('m3c_v3_student_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "ref = db.reference('sep_m3c_hdc_v3/student_results')\n",
        "ref.set(results)\n",
        "\n",
        "print(\"\\nâœ… Results saved!\")\n",
        "print(json.dumps(results, indent=2))"
      ],
      "metadata": {
        "id": "save_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('m3c_v3_student_results.json')\n",
        "files.download('m3c_v3_student_results.png')"
      ],
      "metadata": {
        "id": "download"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
