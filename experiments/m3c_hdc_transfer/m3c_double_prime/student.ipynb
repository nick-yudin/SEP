{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“š M3câ€³: TRUE Semantic Knowledge Transfer â€” Student\n",
        "\n",
        "## The Revolutionary Part\n",
        "\n",
        "**This Student has NEVER seen any text.**\n",
        "\n",
        "It receives ONLY:\n",
        "- HDC vectors (4096-dimensional ternary)\n",
        "- Labels (0 or 1)\n",
        "\n",
        "The Student must learn to predict sentiment from PURE MEANING, not words.\n",
        "\n",
        "```\n",
        "Traditional:  text â†’ model â†’ label\n",
        "M3câ€³:         HDC_meaning â†’ simple_classifier â†’ label\n",
        "```\n",
        "\n",
        "**If this works, we've proven that MEANING is a universal, architecture-independent representation.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install -q firebase-admin\n",
        "!pip install -q sentence-transformers\n",
        "print(\"âœ… Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import json\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, db\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "NODE_ID = \"student_hdc\"\n",
        "print(f\"\\nðŸ“š This is {NODE_ID.upper()} â€” Learning from MEANING only\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Firebase credentials\n",
        "FIREBASE_CREDENTIALS = {\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"resonance-m3\",\n",
        "  \"private_key_id\": \"124e2cb57b123eefac08b105c14afa647d3f90e6\",\n",
        "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDMy0nOWX9JaQWk\\nRS3Mz+l5ib8wiwORkJ/rK1ekJoFwaQA3LKM9F1LhAIIRd/cv7X8cfmK5S84g5Yv7\\nrYRMqBVTqItfwC8bET6i6Sf4ooxwwFuIO6qMBUCju3Yqf+ri5gP6GLdKE2cIdGZe\\nSefMIMe8qql609Dnn6BZ7QrKjgEhgd/byYcLuuFoKNTKYSIw++TqmaRBATEOpI4c\\nstCtx42rhp3Rq03ZpNfGDo67Ua0dCzto1NKkScCfUlgLd3v5OrQuU/37a9vgsoEE\\nmcnWxEpjj8Edd4O+KKt0jbduDcMLbKoe42Csrh11VdIRxtJhn0W3dWcb63ZIN1cV\\nBdlR2VsDAgMBAAECggEAG5NsDBsaUU+Q8OkCcnJfOnxagDYtHtazPJQI0xOpmPH/\\n6MNb9QfvowMnKyRU5ovmR8yaN9/bO6wXyKXkC1EUE2sTNADJga2KxPOm7DXcZKT3\\ng5qf1lwxXgVfXfhSL9ylFcdqNtFHWGjEDVeKR371Jj8ctGtSf+iLS6XoLr98VinM\\na7hvEQBy7Y8wUcugrnv08uzvGPDR+MjcLPZ6YIotDgATklbbv2bZf27ZvhZb666J\\nCS/KhqrS9F/6gTxGjxkJ7EGr14apXcLYnyl4WnlnorDOF87U9eCUh/QPSJmNqrbQ\\nP42ZgJkjgclPMnuLHJFtck0LAP6JbJG2KGkn2BMEIQKBgQDss52wA58/73nlVPZX\\nS9jfmFZX79zCqUr8aipeZ9FKbG2yJ/N3MkW6UdeJfPJpxtYyyzKsZy14sLx5Tiii\\nJ3VenhFJm/9CnnyMdGKl4khHpCxQm3whAMVQJmngTAWdK/jSxG7sXvXsBcOYJEr5\\n9nTUqbhx9cQZ5wX0CBpTShKTewKBgQDdfbSWdA6ZCf+ptdvRxtoCqmDKYIAdH1rH\\nbaUvXfJPTzGhO0uNhdGyOe8om67xRu9U8DqOBZD38l5IES5dtxf7Yiqau3KHh/t6\\n73/kJ6UfskhcR6pKkFv1AH5BoxS2BgCChMZO4B87bU3Z5IILvjbbd/7oK8aNqfRo\\nMPhHx16cGQKBgQCzr9raHrXK3GnlzWzAcmStwMBzOzSUVd4F5jZJungoDk3r++YY\\nK4LBYZXE2qRP5lD++EB8nkrnnwtE7y9rgZbZABfRkGnj0dps6YFlunTyZc/6VT6S\\n8znWkYK4ch2k5hebMOGf8KqxxOJp4ctFHHIuarUJVe/LVhSv32LUrZuSdwKBgQCU\\n6BosvEHEKbC0TAtI8UNIX3tLE62N5rKFOPXA7owlPbzEBLU6pCjihYh/6Iqos2Pb\\n2tXC/YME7vDryoE9iAabftfdxv+sloM/lxyIKw8cTCPRxmx6TKtF/9riDd2ysj5N\\ngS5BgPP+Y/He931mn68JxZaeSC/otcYW9jU1LJgyoQKBgDd8YwxP5YkcRnJzIWAe\\n6CMhYOTNxAKnVwSBNctSG4ztzRa+wRSp0G8YNJCmwKKN7xXfJQGLVD8Shq7cfDY2\\nU+0s3jEzbiIqY9W+FQy3dNsfxxR5WK9isG9fWSFfSg4ichXtTGim2eyKxoxlak2+\\nyvvxzpjUtPKMdW2Sp0HkuS13\\n-----END PRIVATE KEY-----\\n\",\n",
        "  \"client_email\": \"firebase-adminsdk-fbsvc@resonance-m3.iam.gserviceaccount.com\",\n",
        "  \"client_id\": \"103650910750904165580\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-fbsvc%40resonance-m3.iam.gserviceaccount.com\",\n",
        "  \"universe_domain\": \"googleapis.com\"\n",
        "}\n",
        "\n",
        "FIREBASE_DATABASE_URL = \"https://resonance-m3-default-rtdb.europe-west1.firebasedatabase.app\"\n",
        "\n",
        "if not firebase_admin._apps:\n",
        "    cred = credentials.Certificate(FIREBASE_CREDENTIALS)\n",
        "    firebase_admin.initialize_app(cred, {\n",
        "        'databaseURL': FIREBASE_DATABASE_URL\n",
        "    })\n",
        "print(\"âœ… Firebase initialized\")"
      ],
      "metadata": {
        "id": "firebase"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Download HDC Knowledge Packet\n",
        "\n",
        "Remember: This packet contains ONLY HDC vectors and labels. NO TEXT!"
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ“¡ Checking for Teacher's HDC Knowledge Packet...\")\n",
        "\n",
        "ref = db.reference('sep_m3c_hdc/status')\n",
        "status = ref.get()\n",
        "\n",
        "if status and status.get('teacher_ready', False):\n",
        "    print(f\"âœ… Teacher is ready!\")\n",
        "    print(f\"   HDC dimension: {status.get('hdc_dim')}\")\n",
        "    print(f\"   Examples: {status.get('num_examples')}\")\n",
        "    print(f\"   Teacher accuracy: {status.get('teacher_accuracy', 0):.1%}\")\n",
        "else:\n",
        "    print(\"âš ï¸ Teacher not ready. Run Teacher notebook first!\")\n",
        "    raise Exception(\"Teacher not ready\")"
      ],
      "metadata": {
        "id": "check_teacher"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸ“¥ Downloading HDC Knowledge Packet...\")\n",
        "\n",
        "ref = db.reference('sep_m3c_hdc/knowledge_packet')\n",
        "knowledge_packet = ref.get()\n",
        "\n",
        "if not knowledge_packet:\n",
        "    raise Exception(\"Knowledge packet not found!\")\n",
        "\n",
        "HDC_DIM = knowledge_packet['hdc_dim']\n",
        "teacher_acc_before = knowledge_packet['teacher_accuracy_before']\n",
        "teacher_acc_after = knowledge_packet['teacher_accuracy_after']\n",
        "\n",
        "print(f\"\\nðŸ“‹ Knowledge Packet:\")\n",
        "print(f\"   Experiment: {knowledge_packet['experiment']}\")\n",
        "print(f\"   Teacher: {knowledge_packet['teacher_model']}\")\n",
        "print(f\"   Teacher accuracy: {teacher_acc_before:.1%} â†’ {teacher_acc_after:.1%}\")\n",
        "print(f\"   HDC dimension: {HDC_DIM}\")\n",
        "print(f\"   Examples: {knowledge_packet['num_examples']}\")\n",
        "print(f\"\\nâš ï¸  NOTE: {knowledge_packet['note']}\")"
      ],
      "metadata": {
        "id": "download_packet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decompress_hdc_packet(compressed_examples, hdc_dim):\n",
        "    \"\"\"\n",
        "    Decompress HDC vectors from base64 packed format.\n",
        "    \"\"\"\n",
        "    examples = []\n",
        "    \n",
        "    for ex in tqdm(compressed_examples, desc=\"Decompressing HDC vectors\"):\n",
        "        # Decode base64\n",
        "        packed = np.frombuffer(base64.b64decode(ex['hdc_packed']), dtype=np.uint8)\n",
        "        \n",
        "        # Unpack 4 values per byte\n",
        "        unpacked = np.zeros(hdc_dim, dtype=np.int8)\n",
        "        for j in range(4):\n",
        "            unpacked[j::4] = (packed >> (j * 2)) & 0b11\n",
        "        \n",
        "        # Unmap: 0 â†’ -1, 1 â†’ 0, 2 â†’ 1\n",
        "        hdc_vec = unpacked.astype(np.int8) - 1\n",
        "        \n",
        "        examples.append({\n",
        "            'hdc_vector': hdc_vec,\n",
        "            'label': ex['label']\n",
        "        })\n",
        "    \n",
        "    return examples\n",
        "\n",
        "# Decompress\n",
        "hdc_examples = decompress_hdc_packet(knowledge_packet['examples'], HDC_DIM)\n",
        "\n",
        "print(f\"\\nâœ… Decompressed {len(hdc_examples)} HDC examples\")\n",
        "print(f\"   Vector shape: {hdc_examples[0]['hdc_vector'].shape}\")\n",
        "print(f\"   Vector values: {np.unique(hdc_examples[0]['hdc_vector'])}\")"
      ],
      "metadata": {
        "id": "decompress"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Prepare HDC Encoder for Test Data\n",
        "\n",
        "We need the same HDC encoder to encode test texts for evaluation."
      ],
      "metadata": {
        "id": "encoder_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HDCEncoder:\n",
        "    \"\"\"Same HDC Encoder as Teacher - must use same seed!\"\"\"\n",
        "    \n",
        "    def __init__(self, dim=4096, seed=42):\n",
        "        self.dim = dim\n",
        "        self.rng = np.random.RandomState(seed)\n",
        "        \n",
        "        self.semantic_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.semantic_dim = 384\n",
        "        \n",
        "        # MUST use same projection as Teacher\n",
        "        self.projection = self.rng.randn(self.semantic_dim, self.dim).astype(np.float32)\n",
        "        self.projection /= np.linalg.norm(self.projection, axis=0, keepdims=True)\n",
        "        \n",
        "        print(f\"âœ… HDC Encoder initialized (dim={dim})\")\n",
        "    \n",
        "    def encode(self, texts, quantize=True):\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "        \n",
        "        semantic_vecs = self.semantic_encoder.encode(\n",
        "            texts, convert_to_numpy=True, show_progress_bar=False\n",
        "        )\n",
        "        hdc_vecs = semantic_vecs @ self.projection\n",
        "        \n",
        "        if quantize:\n",
        "            threshold = 0.3 * np.std(hdc_vecs, axis=1, keepdims=True)\n",
        "            hdc_vecs = np.where(hdc_vecs > threshold, 1,\n",
        "                       np.where(hdc_vecs < -threshold, -1, 0)).astype(np.int8)\n",
        "        \n",
        "        return hdc_vecs\n",
        "\n",
        "# Initialize with SAME seed as Teacher\n",
        "hdc_encoder = HDCEncoder(dim=HDC_DIM, seed=42)"
      ],
      "metadata": {
        "id": "hdc_encoder"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Create Student Model\n",
        "\n",
        "The Student is a simple classifier that takes HDC vectors as input.\n",
        "\n",
        "**NO language model! NO tokenizer! Just: HDC vector â†’ label**"
      ],
      "metadata": {
        "id": "student_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HDCClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple classifier that takes HDC vectors as input.\n",
        "    \n",
        "    This is NOT a language model. It learns:\n",
        "    HDC_meaning_vector â†’ sentiment_label\n",
        "    \n",
        "    It has never seen text and never will.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, hdc_dim, hidden_dim=512, num_classes=2, dropout=0.3):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hdc_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, num_classes)\n",
        "        )\n",
        "        \n",
        "        # Count parameters\n",
        "        self.num_params = sum(p.numel() for p in self.parameters())\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Create Student\n",
        "student = HDCClassifier(hdc_dim=HDC_DIM, hidden_dim=512).to(device)\n",
        "\n",
        "print(f\"\\nðŸ“š Student Model: HDC Classifier\")\n",
        "print(f\"   Input: HDC vector ({HDC_DIM} dimensions)\")\n",
        "print(f\"   Output: 2 classes (positive/negative)\")\n",
        "print(f\"   Parameters: {student.num_params:,}\")\n",
        "print(f\"\\nâš ï¸  This model has NEVER seen text!\")\n",
        "print(f\"   It only knows: HDC_meaning â†’ label\")"
      ],
      "metadata": {
        "id": "student_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Prepare Test Data\n",
        "\n",
        "We need to encode test texts to HDC vectors for evaluation."
      ],
      "metadata": {
        "id": "test_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading SST-2 test dataset...\")\n",
        "dataset = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "TEST_SIZE = 500\n",
        "test_texts = dataset['validation']['sentence'][:TEST_SIZE]\n",
        "test_labels = dataset['validation']['label'][:TEST_SIZE]\n",
        "\n",
        "print(f\"âœ… Loaded {len(test_texts)} test examples\")\n",
        "\n",
        "# Encode test texts to HDC vectors\n",
        "print(\"\\nðŸ”„ Encoding test texts to HDC vectors...\")\n",
        "test_hdc = []\n",
        "batch_size = 64\n",
        "\n",
        "for i in tqdm(range(0, len(test_texts), batch_size), desc=\"Encoding\"):\n",
        "    batch = list(test_texts[i:i+batch_size])\n",
        "    hdc_vecs = hdc_encoder.encode(batch, quantize=True)\n",
        "    test_hdc.extend(hdc_vecs)\n",
        "\n",
        "test_hdc = np.array(test_hdc)\n",
        "print(f\"âœ… Test HDC vectors shape: {test_hdc.shape}\")"
      ],
      "metadata": {
        "id": "prepare_test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders\n",
        "class HDCDataset(Dataset):\n",
        "    def __init__(self, hdc_vectors, labels):\n",
        "        self.hdc = torch.tensor(hdc_vectors, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.hdc[idx], self.labels[idx]\n",
        "\n",
        "# Training data from Teacher's knowledge\n",
        "train_hdc_vecs = np.array([ex['hdc_vector'] for ex in hdc_examples])\n",
        "train_labels = np.array([ex['label'] for ex in hdc_examples])\n",
        "\n",
        "train_dataset = HDCDataset(train_hdc_vecs, train_labels)\n",
        "test_dataset = HDCDataset(test_hdc, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(f\"\\nðŸ“Š Datasets:\")\n",
        "print(f\"   Train (from Teacher): {len(train_dataset)} HDC vectors\")\n",
        "print(f\"   Test: {len(test_dataset)} HDC vectors\")"
      ],
      "metadata": {
        "id": "create_loaders"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Measure Student BEFORE Training"
      ],
      "metadata": {
        "id": "before_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for hdc, labels in dataloader:\n",
        "            hdc = hdc.to(device)\n",
        "            outputs = model(hdc)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "    \n",
        "    return accuracy_score(all_labels, all_preds)\n",
        "\n",
        "print(\"ðŸ“Š Measuring Student BEFORE training...\")\n",
        "acc_before = evaluate(student, test_loader)\n",
        "print(f\"âœ… Student accuracy BEFORE: {acc_before:.4f} ({acc_before:.1%})\")\n",
        "print(f\"   (Random baseline: 50%)\")"
      ],
      "metadata": {
        "id": "before_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Train Student on HDC Vectors\n",
        "\n",
        "**THE STUDENT LEARNS FROM MEANING ONLY!**\n",
        "\n",
        "Input: HDC vector (4096 ternary values)\n",
        "Output: Sentiment (positive/negative)\n",
        "\n",
        "No text. No words. Only meaning."
      ],
      "metadata": {
        "id": "train_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ§  TRAINING STUDENT ON PURE MEANING\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nâš ï¸  Student input: HDC vectors ({HDC_DIM}d ternary)\")\n",
        "print(f\"   Student output: sentiment label\")\n",
        "print(f\"   Student has NEVER seen text!\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Training setup\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(student.parameters(), lr=1e-3, weight_decay=0.01)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "history = {'train_loss': [], 'train_acc': [], 'test_acc': []}\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Training\n",
        "    student.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for hdc, labels in train_loader:\n",
        "        hdc = hdc.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = student(hdc)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    \n",
        "    scheduler.step()\n",
        "    \n",
        "    train_loss = total_loss / len(train_loader)\n",
        "    train_acc = correct / total\n",
        "    test_acc = evaluate(student, test_loader)\n",
        "    \n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['test_acc'].append(test_acc)\n",
        "    \n",
        "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "        print(f\"Epoch {epoch+1:2d}/{NUM_EPOCHS} | \"\n",
        "              f\"Loss: {train_loss:.4f} | \"\n",
        "              f\"Train: {train_acc:.1%} | \"\n",
        "              f\"Test: {test_acc:.1%}\")\n",
        "\n",
        "print(\"\\nâœ… Training complete!\")"
      ],
      "metadata": {
        "id": "train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Measure Student AFTER Training"
      ],
      "metadata": {
        "id": "after_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ“Š Measuring Student AFTER training...\")\n",
        "acc_after = evaluate(student, test_loader)\n",
        "print(f\"âœ… Student accuracy AFTER: {acc_after:.4f} ({acc_after:.1%})\")"
      ],
      "metadata": {
        "id": "after_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Analyze Results"
      ],
      "metadata": {
        "id": "results_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "student_improvement = acc_after - acc_before\n",
        "teacher_improvement = teacher_acc_after - teacher_acc_before\n",
        "\n",
        "if teacher_improvement > 0:\n",
        "    transfer_efficiency = (student_improvement / teacher_improvement) * 100\n",
        "else:\n",
        "    transfer_efficiency = 0\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š RESULTS: TRUE HDC SEMANTIC TRANSFER\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nðŸŽ“ TEACHER ({knowledge_packet['teacher_model']}):\")\n",
        "print(f\"   Learned from: text\")\n",
        "print(f\"   Accuracy: {teacher_acc_before:.1%} â†’ {teacher_acc_after:.1%} (+{teacher_improvement:.1%})\")\n",
        "\n",
        "print(f\"\\nðŸ“š STUDENT (HDC Classifier):\")\n",
        "print(f\"   Learned from: HDC vectors ONLY (no text!)\")\n",
        "print(f\"   Accuracy: {acc_before:.1%} â†’ {acc_after:.1%} (+{student_improvement:.1%})\")\n",
        "print(f\"   Parameters: {student.num_params:,}\")\n",
        "\n",
        "print(f\"\\nðŸ”„ SEMANTIC TRANSFER:\")\n",
        "print(f\"   Transfer efficiency: {transfer_efficiency:.1f}%\")\n",
        "print(f\"   Knowledge format: HDC ternary vectors ({HDC_DIM}d)\")\n",
        "print(f\"   Text seen by Student: ZERO\")"
      ],
      "metadata": {
        "id": "analyze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verdict\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“‹ VERDICT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if acc_after >= 0.75:\n",
        "    verdict = \"SUCCESS\"\n",
        "    emoji = \"ðŸŽ‰\"\n",
        "    message = \"MEANING IS UNIVERSAL! Student learned sentiment from HDC vectors alone.\"\n",
        "elif acc_after >= 0.65:\n",
        "    verdict = \"GOOD\"\n",
        "    emoji = \"âœ…\"\n",
        "    message = \"Significant learning from meaning. HDC vectors carry semantic information.\"\n",
        "elif acc_after >= 0.55:\n",
        "    verdict = \"PARTIAL\"\n",
        "    emoji = \"âš ï¸\"\n",
        "    message = \"Some learning, but limited. HDC encoding may need refinement.\"\n",
        "else:\n",
        "    verdict = \"FAILED\"\n",
        "    emoji = \"âŒ\"\n",
        "    message = \"Student did not learn from HDC vectors. Need to investigate.\"\n",
        "\n",
        "print(f\"\\n{emoji} {verdict}\")\n",
        "print(f\"\\n{message}\")\n",
        "\n",
        "if verdict in [\"SUCCESS\", \"GOOD\"]:\n",
        "    print(f\"\\nðŸŒŸ KEY INSIGHT:\")\n",
        "    print(f\"   The Student NEVER saw any text.\")\n",
        "    print(f\"   It learned sentiment from MEANING ALONE.\")\n",
        "    print(f\"   This proves HDC vectors encode transferable semantics.\")\n",
        "    print(f\"\\n   MEANING IS THE UNIVERSAL LANGUAGE OF AI.\")"
      ],
      "metadata": {
        "id": "verdict"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Training curves\n",
        "ax = axes[0]\n",
        "ax.plot(history['train_acc'], label='Train', color='blue')\n",
        "ax.plot(history['test_acc'], label='Test', color='orange')\n",
        "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Random')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Student Learning from HDC Vectors')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Comparison bars\n",
        "ax = axes[1]\n",
        "models = ['Teacher\\n(DistilBERT)\\n[sees text]', 'Student\\n(HDC Classifier)\\n[NO text!]']\n",
        "before = [teacher_acc_before, acc_before]\n",
        "after = [teacher_acc_after, acc_after]\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, before, width, label='Before', color='lightcoral')\n",
        "bars2 = ax.bar(x + width/2, after, width, label='After', color='lightgreen')\n",
        "\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Teacher vs Student (Text vs Meaning)')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models)\n",
        "ax.legend()\n",
        "ax.set_ylim(0, 1)\n",
        "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "for bar, val in zip(bars1, before):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
        "            f'{val:.1%}', ha='center', fontsize=10)\n",
        "for bar, val in zip(bars2, after):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "            f'{val:.1%}', ha='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Flow diagram\n",
        "ax = axes[2]\n",
        "ax.set_xlim(0, 1)\n",
        "ax.set_ylim(0, 1)\n",
        "\n",
        "# Teacher path\n",
        "ax.text(0.15, 0.85, 'TEXT', ha='center', fontsize=12, fontweight='bold',\n",
        "        bbox=dict(boxstyle='round', facecolor='lightblue'))\n",
        "ax.annotate('', xy=(0.15, 0.65), xytext=(0.15, 0.78),\n",
        "            arrowprops=dict(arrowstyle='->', color='blue'))\n",
        "ax.text(0.15, 0.55, 'Teacher\\n(DistilBERT)', ha='center', fontsize=10,\n",
        "        bbox=dict(boxstyle='round', facecolor='lightblue'))\n",
        "\n",
        "# HDC encoding\n",
        "ax.annotate('', xy=(0.45, 0.55), xytext=(0.28, 0.55),\n",
        "            arrowprops=dict(arrowstyle='->', color='purple', lw=2))\n",
        "ax.text(0.36, 0.62, 'HDC\\nEncode', ha='center', fontsize=8, color='purple')\n",
        "\n",
        "# HDC vector\n",
        "ax.text(0.55, 0.55, 'HDC\\nMEANING', ha='center', fontsize=12, fontweight='bold',\n",
        "        bbox=dict(boxstyle='round', facecolor='gold'))\n",
        "\n",
        "# Student path\n",
        "ax.annotate('', xy=(0.75, 0.55), xytext=(0.68, 0.55),\n",
        "            arrowprops=dict(arrowstyle='->', color='green', lw=2))\n",
        "ax.text(0.85, 0.55, 'Student\\n(Classifier)', ha='center', fontsize=10,\n",
        "        bbox=dict(boxstyle='round', facecolor='lightgreen'))\n",
        "\n",
        "# Result\n",
        "ax.text(0.5, 0.2, f'Student learned from MEANING only!\\nAccuracy: {acc_after:.1%}',\n",
        "        ha='center', fontsize=12, fontweight='bold',\n",
        "        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n",
        "\n",
        "ax.text(0.5, 0.05, f'Verdict: {verdict}', ha='center', fontsize=14, fontweight='bold')\n",
        "\n",
        "ax.axis('off')\n",
        "ax.set_title('True Semantic Transfer: Text â†’ HDC â†’ Student')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('m3c_hdc_student_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nâœ… Visualization saved\")"
      ],
      "metadata": {
        "id": "visualize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results\n",
        "results = {\n",
        "    'phase': 'M3c_double_prime',\n",
        "    'experiment': 'TRUE HDC Semantic Transfer',\n",
        "    'node': 'student_hdc',\n",
        "    'teacher_model': knowledge_packet['teacher_model'],\n",
        "    'student_model': 'HDC Classifier (no text input)',\n",
        "    'student_params': student.num_params,\n",
        "    'hdc_dim': HDC_DIM,\n",
        "    'hdc_examples': len(hdc_examples),\n",
        "    'test_samples': TEST_SIZE,\n",
        "    'teacher_accuracy_before': float(teacher_acc_before),\n",
        "    'teacher_accuracy_after': float(teacher_acc_after),\n",
        "    'teacher_improvement': float(teacher_improvement),\n",
        "    'student_accuracy_before': float(acc_before),\n",
        "    'student_accuracy_after': float(acc_after),\n",
        "    'student_improvement': float(student_improvement),\n",
        "    'transfer_efficiency_pct': float(transfer_efficiency),\n",
        "    'verdict': verdict,\n",
        "    'key_insight': 'Student learned from HDC vectors ONLY - never saw text',\n",
        "    'timestamp': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "# Save locally\n",
        "with open('m3c_hdc_student_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "# Upload to Firebase\n",
        "ref = db.reference('sep_m3c_hdc/student_results')\n",
        "ref.set(results)\n",
        "\n",
        "print(\"\\nâœ… Results saved\")\n",
        "print(\"\\n\" + json.dumps(results, indent=2))"
      ],
      "metadata": {
        "id": "save_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('m3c_hdc_student_results.json')\n",
        "files.download('m3c_hdc_student_results.png')"
      ],
      "metadata": {
        "id": "download"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ðŸŽ¯ What We Proved (If Successful)\n",
        "\n",
        "1. **MEANING is architecture-independent**\n",
        "   - HDC vectors encode semantic content\n",
        "   - Any classifier can learn from them\n",
        "\n",
        "2. **Text is just a transport, not the essence**\n",
        "   - Teacher saw text â†’ extracted meaning\n",
        "   - Student saw meaning â†’ learned task\n",
        "   - Text was never transmitted!\n",
        "\n",
        "3. **This enables TRUE distributed AI**\n",
        "   - Nodes can have different architectures\n",
        "   - They communicate via MEANING\n",
        "   - No text, no weights â€” just semantics\n",
        "\n",
        "---\n",
        "\n",
        "**MEANING IS ALL YOU NEED**\n"
      ],
      "metadata": {
        "id": "summary"
      }
    }
  ]
}
