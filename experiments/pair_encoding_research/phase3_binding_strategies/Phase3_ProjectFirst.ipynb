{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”¬ Phase 3: Project-First-Bind-Later\n",
        "\n",
        "## Key Insight from Experts\n",
        "Current approach does math in dense 384d/768d space, THEN projects.\n",
        "HDC math works better in high-dimensional space where vectors are quasi-orthogonal.\n",
        "\n",
        "## Architecture Change\n",
        "```\n",
        "OLD: concat(P, H, P-H, P*H) â†’ project â†’ quantize\n",
        "NEW: P â†’ project â†’ P_hdc\n",
        "     H â†’ project â†’ H_hdc\n",
        "     bind(P_hdc, H_hdc) â†’ quantize\n",
        "```\n",
        "\n",
        "## Experiments\n",
        "1. Basic: P_hdc + H_hdc + P_hdc*H_hdc\n",
        "2. With permutation: roll(P_hdc) * H_hdc (asymmetry)\n",
        "3. With tanh: non-linearity before binding\n",
        "4. Two-vector: [P_hdc, H_hdc, diff, prod] â†’ MLP\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentence-transformers datasets\n",
        "print(\"âœ… Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"\\nðŸ”¬ Phase 3: Project-First-Bind-Later\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use best encoder from Phase 2\n",
        "ENCODER_NAME = 'sentence-transformers/nli-mpnet-base-v2'\n",
        "print(f\"Loading {ENCODER_NAME}...\")\n",
        "encoder = SentenceTransformer(ENCODER_NAME)\n",
        "SEMANTIC_DIM = encoder.get_sentence_embedding_dimension()\n",
        "print(f\"âœ… Encoder loaded: {SEMANTIC_DIM}d\")"
      ],
      "metadata": {
        "id": "encoder"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNLI\n",
        "print(\"\\nLoading MNLI...\")\n",
        "dataset = load_dataset(\"glue\", \"mnli\")\n",
        "\n",
        "TRAIN_SIZE = 5000\n",
        "TEST_SIZE = 500\n",
        "\n",
        "train_data = dataset['train'].shuffle(seed=42).select(range(TRAIN_SIZE))\n",
        "test_data = dataset['validation_matched'].select(range(TEST_SIZE))\n",
        "\n",
        "train_labels = np.array(train_data['label'])\n",
        "test_labels = np.array(test_data['label'])\n",
        "\n",
        "print(f\"âœ… Train: {TRAIN_SIZE}, Test: {TEST_SIZE}\")"
      ],
      "metadata": {
        "id": "load_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-compute embeddings\n",
        "print(\"\\nðŸ”„ Computing embeddings...\")\n",
        "\n",
        "train_p = encoder.encode(list(train_data['premise']), show_progress_bar=True)\n",
        "train_h = encoder.encode(list(train_data['hypothesis']), show_progress_bar=True)\n",
        "test_p = encoder.encode(list(test_data['premise']), show_progress_bar=True)\n",
        "test_h = encoder.encode(list(test_data['hypothesis']), show_progress_bar=True)\n",
        "\n",
        "print(f\"âœ… Embeddings: {train_p.shape}\")"
      ],
      "metadata": {
        "id": "embeddings"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HDC Configuration\n",
        "HDC_DIM = 4096\n",
        "\n",
        "# Create projection matrix (same for both P and H)\n",
        "np.random.seed(42)\n",
        "projection = np.random.randn(SEMANTIC_DIM, HDC_DIM).astype(np.float32)\n",
        "projection /= np.linalg.norm(projection, axis=0, keepdims=True)\n",
        "\n",
        "print(f\"âœ… Projection matrix: {projection.shape}\")"
      ],
      "metadata": {
        "id": "projection"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ternary_quantize(features, threshold_factor=0.3):\n",
        "    \"\"\"Quantize to {-1, 0, +1}.\"\"\"\n",
        "    thr = threshold_factor * np.std(features, axis=1, keepdims=True)\n",
        "    return np.where(features > thr, 1,\n",
        "                    np.where(features < -thr, -1, 0)).astype(np.float32)"
      ],
      "metadata": {
        "id": "quantize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Encoding Strategies: Project-First-Bind-Later\n",
        "---"
      ],
      "metadata": {
        "id": "strategies_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectFirstStrategies:\n",
        "    \"\"\"Different binding strategies after projection to HDC space.\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def baseline_concat(p_emb, h_emb, projection):\n",
        "        \"\"\"OLD approach: concat first, then project (for comparison).\"\"\"\n",
        "        combined = np.concatenate([p_emb, h_emb, p_emb - h_emb, p_emb * h_emb], axis=1)\n",
        "        # Need different projection for this\n",
        "        np.random.seed(42)\n",
        "        proj_big = np.random.randn(combined.shape[1], HDC_DIM).astype(np.float32)\n",
        "        proj_big /= np.linalg.norm(proj_big, axis=0, keepdims=True)\n",
        "        return combined @ proj_big\n",
        "    \n",
        "    @staticmethod\n",
        "    def project_then_bundle(p_emb, h_emb, projection):\n",
        "        \"\"\"Project first, then bundle (sum).\"\"\"\n",
        "        p_hdc = p_emb @ projection\n",
        "        h_hdc = h_emb @ projection\n",
        "        # Bundle: P + H + (P * H)\n",
        "        binding = p_hdc * h_hdc\n",
        "        return p_hdc + h_hdc + binding\n",
        "    \n",
        "    @staticmethod\n",
        "    def project_permute_bind(p_emb, h_emb, projection):\n",
        "        \"\"\"Project first, permute P for asymmetry, then bind.\"\"\"\n",
        "        p_hdc = p_emb @ projection\n",
        "        h_hdc = h_emb @ projection\n",
        "        # Permute P to encode direction (Pâ†’H â‰  Hâ†’P)\n",
        "        p_rotated = np.roll(p_hdc, shift=1, axis=1)\n",
        "        binding = p_rotated * h_hdc\n",
        "        return p_hdc + h_hdc + binding\n",
        "    \n",
        "    @staticmethod\n",
        "    def project_tanh_bind(p_emb, h_emb, projection):\n",
        "        \"\"\"Project, apply tanh, then bind.\"\"\"\n",
        "        p_hdc = np.tanh(p_emb @ projection)\n",
        "        h_hdc = np.tanh(h_emb @ projection)\n",
        "        binding = p_hdc * h_hdc\n",
        "        return p_hdc + h_hdc + binding\n",
        "    \n",
        "    @staticmethod\n",
        "    def project_tanh_permute_bind(p_emb, h_emb, projection):\n",
        "        \"\"\"Project, tanh, permute, bind â€” full approach.\"\"\"\n",
        "        p_hdc = np.tanh(p_emb @ projection)\n",
        "        h_hdc = np.tanh(h_emb @ projection)\n",
        "        p_rotated = np.roll(p_hdc, shift=1, axis=1)\n",
        "        binding = p_rotated * h_hdc\n",
        "        return p_hdc + h_hdc + binding\n",
        "    \n",
        "    @staticmethod\n",
        "    def two_vectors_concat(p_emb, h_emb, projection):\n",
        "        \"\"\"Project separately, concat with interactions for MLP.\"\"\"\n",
        "        p_hdc = p_emb @ projection\n",
        "        h_hdc = h_emb @ projection\n",
        "        diff = p_hdc - h_hdc\n",
        "        prod = p_hdc * h_hdc\n",
        "        # Concat all: 4 * HDC_DIM = 16384d\n",
        "        return np.concatenate([p_hdc, h_hdc, diff, prod], axis=1)\n",
        "    \n",
        "    @staticmethod\n",
        "    def two_vectors_tanh(p_emb, h_emb, projection):\n",
        "        \"\"\"Same as above but with tanh.\"\"\"\n",
        "        p_hdc = np.tanh(p_emb @ projection)\n",
        "        h_hdc = np.tanh(h_emb @ projection)\n",
        "        diff = p_hdc - h_hdc\n",
        "        prod = p_hdc * h_hdc\n",
        "        return np.concatenate([p_hdc, h_hdc, diff, prod], axis=1)\n",
        "\n",
        "# Strategies to test\n",
        "STRATEGIES = {\n",
        "    '0_baseline_concat': (ProjectFirstStrategies.baseline_concat, HDC_DIM),\n",
        "    '1_project_bundle': (ProjectFirstStrategies.project_then_bundle, HDC_DIM),\n",
        "    '2_project_permute': (ProjectFirstStrategies.project_permute_bind, HDC_DIM),\n",
        "    '3_project_tanh': (ProjectFirstStrategies.project_tanh_bind, HDC_DIM),\n",
        "    '4_project_tanh_permute': (ProjectFirstStrategies.project_tanh_permute_bind, HDC_DIM),\n",
        "    '5_two_vectors': (ProjectFirstStrategies.two_vectors_concat, HDC_DIM * 4),\n",
        "    '6_two_vectors_tanh': (ProjectFirstStrategies.two_vectors_tanh, HDC_DIM * 4),\n",
        "}\n",
        "\n",
        "print(\"ðŸ“‹ Strategies to test:\")\n",
        "for name, (_, dim) in STRATEGIES.items():\n",
        "    print(f\"   {name}: {dim}d\")"
      ],
      "metadata": {
        "id": "strategies"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and Model\n",
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=512, num_classes=3, dropout=0.3):\n",
        "        super().__init__()\n",
        "        # Adjust hidden dim for larger inputs\n",
        "        if input_dim > 8000:\n",
        "            hidden_dim = 1024\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.classifier(x)\n",
        "\n",
        "def train_and_evaluate(train_features, train_labels, test_features, test_labels,\n",
        "                       input_dim, num_epochs=25, lr=1e-3):\n",
        "    \"\"\"Train MLP and return best accuracy.\"\"\"\n",
        "    \n",
        "    train_dataset = SimpleDataset(train_features, train_labels)\n",
        "    test_dataset = SimpleDataset(test_features, test_labels)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "    \n",
        "    model = MLPClassifier(input_dim=input_dim).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "    \n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for features, labels in train_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(features), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        with torch.no_grad():\n",
        "            for features, _ in test_loader:\n",
        "                features = features.to(device)\n",
        "                preds = torch.argmax(model(features), dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "        \n",
        "        acc = accuracy_score(test_labels, all_preds)\n",
        "        best_acc = max(best_acc, acc)\n",
        "    \n",
        "    return best_acc"
      ],
      "metadata": {
        "id": "model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ”¬ TESTING PROJECT-FIRST-BIND-LATER STRATEGIES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for strategy_name, (strategy_fn, output_dim) in STRATEGIES.items():\n",
        "    print(f\"\\nðŸ“Š Testing: {strategy_name}\")\n",
        "    \n",
        "    # Apply strategy\n",
        "    train_encoded = strategy_fn(train_p, train_h, projection)\n",
        "    test_encoded = strategy_fn(test_p, test_h, projection)\n",
        "    \n",
        "    # Test float version\n",
        "    print(f\"   Float ({output_dim}d)...\")\n",
        "    acc_float = train_and_evaluate(train_encoded, train_labels,\n",
        "                                    test_encoded, test_labels, output_dim)\n",
        "    print(f\"   Float: {acc_float:.1%}\")\n",
        "    \n",
        "    # Test ternary version\n",
        "    print(f\"   Ternary...\")\n",
        "    train_ternary = ternary_quantize(train_encoded)\n",
        "    test_ternary = ternary_quantize(test_encoded)\n",
        "    acc_ternary = train_and_evaluate(train_ternary, train_labels,\n",
        "                                      test_ternary, test_labels, output_dim)\n",
        "    print(f\"   Ternary: {acc_ternary:.1%}\")\n",
        "    \n",
        "    results[strategy_name] = {\n",
        "        'float': acc_float,\n",
        "        'ternary': acc_ternary,\n",
        "        'dim': output_dim,\n",
        "        'overhead': acc_float - acc_ternary\n",
        "    }\n",
        "    \n",
        "    print(f\"   âœ… Overhead: {(acc_float - acc_ternary)*100:.1f}%\")"
      ],
      "metadata": {
        "id": "run_experiments"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Sort by ternary accuracy\n",
        "sorted_results = sorted(results.items(), key=lambda x: x[1]['ternary'], reverse=True)\n",
        "\n",
        "print(f\"\\n{'Strategy':<30} {'Dim':<8} {'Float':<10} {'Ternary':<10} {'Overhead'}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "baseline_ternary = results['0_baseline_concat']['ternary']\n",
        "\n",
        "for name, data in sorted_results:\n",
        "    marker = \"ðŸ†\" if data['ternary'] == sorted_results[0][1]['ternary'] else \"  \"\n",
        "    improvement = (data['ternary'] - baseline_ternary) * 100\n",
        "    print(f\"{marker} {name:<28} {data['dim']:<8} {data['float']:.1%}      {data['ternary']:.1%}      {data['overhead']*100:.1f}%\")"
      ],
      "metadata": {
        "id": "summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find best\n",
        "best_strategy = sorted_results[0][0]\n",
        "best_ternary = sorted_results[0][1]['ternary']\n",
        "best_float = sorted_results[0][1]['float']\n",
        "\n",
        "# Phase 2 best for comparison\n",
        "phase2_best = 0.638  # NLI-MPNet full HDC\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ¯ CONCLUSIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nðŸ† Best strategy: {best_strategy}\")\n",
        "print(f\"   Float: {best_float:.1%}\")\n",
        "print(f\"   Ternary: {best_ternary:.1%}\")\n",
        "print(f\"\\nðŸ“ˆ vs Phase 2 best ({phase2_best:.1%}): {(best_ternary - phase2_best)*100:+.1f}%\")\n",
        "print(f\"ðŸ“ˆ vs Baseline concat: {(best_ternary - baseline_ternary)*100:+.1f}%\")\n",
        "\n",
        "if best_ternary > 0.70:\n",
        "    print(f\"\\nâœ… SIGNIFICANT IMPROVEMENT! Exceeded 70% target.\")\n",
        "    verdict = \"TARGET_REACHED\"\n",
        "elif best_ternary > phase2_best + 0.03:\n",
        "    print(f\"\\nðŸ“ˆ Good improvement over Phase 2.\")\n",
        "    verdict = \"IMPROVEMENT\"\n",
        "else:\n",
        "    print(f\"\\nâš ï¸ Limited improvement. May need different approach.\")\n",
        "    verdict = \"LIMITED\""
      ],
      "metadata": {
        "id": "conclusions"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bar chart\n",
        "ax = axes[0]\n",
        "names = [n.replace('_', '\\n') for n, _ in sorted_results]\n",
        "float_accs = [d['float'] for _, d in sorted_results]\n",
        "tern_accs = [d['ternary'] for _, d in sorted_results]\n",
        "\n",
        "x = np.arange(len(names))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, float_accs, width, label='Float', color='lightgreen', edgecolor='black')\n",
        "bars2 = ax.bar(x + width/2, tern_accs, width, label='Ternary', color='lightcoral', edgecolor='black')\n",
        "\n",
        "ax.axhline(y=phase2_best, color='blue', linestyle='--', label=f'Phase 2 best ({phase2_best:.1%})')\n",
        "ax.axhline(y=0.33, color='gray', linestyle=':', alpha=0.5)\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Project-First-Bind-Later Strategies')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(names, fontsize=8)\n",
        "ax.legend(loc='lower right')\n",
        "ax.set_ylim(0.3, max(float_accs) + 0.05)\n",
        "\n",
        "# Improvement chart\n",
        "ax = axes[1]\n",
        "improvements = [(d['ternary'] - baseline_ternary) * 100 for _, d in sorted_results]\n",
        "colors = ['lightgreen' if i > 0 else 'lightcoral' for i in improvements]\n",
        "bars = ax.bar(names, improvements, color=colors, edgecolor='black')\n",
        "ax.axhline(y=0, color='black', linewidth=0.5)\n",
        "ax.axhline(y=(phase2_best - baseline_ternary) * 100, color='blue', linestyle='--', \n",
        "           label=f'Phase 2 improvement')\n",
        "ax.set_ylabel('Improvement vs Baseline (%)')\n",
        "ax.set_title('Improvement over Baseline Concat')\n",
        "ax.set_xticklabels(names, fontsize=8, rotation=45, ha='right')\n",
        "\n",
        "for bar, imp in zip(bars, improvements):\n",
        "    y_pos = bar.get_height() + 0.5 if imp >= 0 else bar.get_height() - 1\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, y_pos,\n",
        "            f'{imp:+.1f}%', ha='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('phase3_project_first_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "visualize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results\n",
        "output = {\n",
        "    'experiment': 'Phase 3: Project-First-Bind-Later',\n",
        "    'dataset': 'MNLI',\n",
        "    'encoder': ENCODER_NAME,\n",
        "    'train_size': TRAIN_SIZE,\n",
        "    'test_size': TEST_SIZE,\n",
        "    'hdc_dim': HDC_DIM,\n",
        "    'results': {k: {kk: float(vv) if isinstance(vv, (np.floating, float)) else vv \n",
        "                    for kk, vv in v.items()} \n",
        "                for k, v in results.items()},\n",
        "    'best_strategy': best_strategy,\n",
        "    'best_float': float(best_float),\n",
        "    'best_ternary': float(best_ternary),\n",
        "    'phase2_best': phase2_best,\n",
        "    'improvement_vs_phase2': float(best_ternary - phase2_best),\n",
        "    'verdict': verdict,\n",
        "    'timestamp': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "with open('phase3_project_first_results.json', 'w') as f:\n",
        "    json.dump(output, f, indent=2)\n",
        "\n",
        "print(\"\\nâœ… Results saved!\")\n",
        "print(json.dumps(output, indent=2))"
      ],
      "metadata": {
        "id": "save"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“‹ NEXT STEPS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\"\"\n",
        "Current best: {best_ternary:.1%} ({best_strategy})\n",
        "\n",
        "Options to try next:\n",
        "1. Role-Filler Binding (VSA-style)\n",
        "2. Increase HDC dimension (8192d)\n",
        "3. Learned projection matrix\n",
        "4. Circular convolution instead of element-wise mult\n",
        "5. Combine best strategies\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "next_steps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('phase3_project_first_results.json')\n",
        "files.download('phase3_project_first_results.png')"
      ],
      "metadata": {
        "id": "download"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
