{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”¬ Phase 1: Ablation Study â€” Where is Information Lost?\n",
        "\n",
        "## Goal\n",
        "Understand exactly WHERE the 37% gap comes from:\n",
        "- Pair features themselves?\n",
        "- Random projection?\n",
        "- Ternary quantization?\n",
        "- Combination?\n",
        "\n",
        "## Experiments\n",
        "| Config | Description | Dims |\n",
        "|--------|-------------|------|\n",
        "| A | 1536-float (no HDC) | 1536 |\n",
        "| B | 4096-float (projection only) | 4096 |\n",
        "| C | 1536-ternary (quantization only) | 1536 |\n",
        "| D | 4096-ternary (full HDC) | 4096 |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentence-transformers datasets\n",
        "print(\"âœ… Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"\\nðŸ”¬ Phase 1: Ablation Study\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load encoder\n",
        "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "SEMANTIC_DIM = 384\n",
        "print(f\"âœ… Encoder: {SEMANTIC_DIM}d\")"
      ],
      "metadata": {
        "id": "encoder"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNLI\n",
        "print(\"Loading MNLI...\")\n",
        "dataset = load_dataset(\"glue\", \"mnli\")\n",
        "\n",
        "TRAIN_SIZE = 5000\n",
        "TEST_SIZE = 500\n",
        "\n",
        "train_data = dataset['train'].shuffle(seed=42).select(range(TRAIN_SIZE))\n",
        "test_data = dataset['validation_matched'].select(range(TEST_SIZE))\n",
        "\n",
        "train_labels = np.array(train_data['label'])\n",
        "test_labels = np.array(test_data['label'])\n",
        "\n",
        "print(f\"âœ… Train: {TRAIN_SIZE}, Test: {TEST_SIZE}\")"
      ],
      "metadata": {
        "id": "load_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-compute embeddings\n",
        "print(\"\\nðŸ”„ Computing embeddings...\")\n",
        "\n",
        "train_p = encoder.encode(train_data['premise'], show_progress_bar=True)\n",
        "train_h = encoder.encode(train_data['hypothesis'], show_progress_bar=True)\n",
        "test_p = encoder.encode(test_data['premise'], show_progress_bar=True)\n",
        "test_h = encoder.encode(test_data['hypothesis'], show_progress_bar=True)\n",
        "\n",
        "print(f\"âœ… Embeddings: {train_p.shape}\")"
      ],
      "metadata": {
        "id": "compute_embeddings"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pair features (best from previous experiments: diff + prod)\n",
        "def make_pair_features(p, h, method='full'):\n",
        "    \"\"\"Create pair features.\"\"\"\n",
        "    if method == 'full':\n",
        "        # [P, H, P-H, P*H] = 1536d\n",
        "        return np.concatenate([p, h, p - h, p * h], axis=1)\n",
        "    elif method == 'diff_prod':\n",
        "        # [P-H, P*H] = 768d (best from encoding strategies)\n",
        "        return np.concatenate([p - h, p * h], axis=1)\n",
        "\n",
        "# Use full features for ablation\n",
        "train_features = make_pair_features(train_p, train_h, 'full')\n",
        "test_features = make_pair_features(test_p, test_h, 'full')\n",
        "\n",
        "print(f\"âœ… Pair features: {train_features.shape}\")"
      ],
      "metadata": {
        "id": "pair_features"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformation functions\n",
        "def random_projection(features, dim=4096, seed=42):\n",
        "    \"\"\"Random projection to higher dimension.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    proj = np.random.randn(features.shape[1], dim).astype(np.float32)\n",
        "    proj /= np.linalg.norm(proj, axis=0, keepdims=True)\n",
        "    return features @ proj\n",
        "\n",
        "def ternary_quantize(features):\n",
        "    \"\"\"Quantize to {-1, 0, +1}.\"\"\"\n",
        "    thr = 0.3 * np.std(features, axis=1, keepdims=True)\n",
        "    return np.where(features > thr, 1,\n",
        "                    np.where(features < -thr, -1, 0)).astype(np.float32)\n",
        "\n",
        "print(\"âœ… Transformation functions ready\")"
      ],
      "metadata": {
        "id": "transforms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare all 4 configurations\n",
        "HDC_DIM = 4096\n",
        "\n",
        "configs = {\n",
        "    'A: 1536-float (no HDC)': {\n",
        "        'train': train_features,\n",
        "        'test': test_features,\n",
        "        'dim': 1536\n",
        "    },\n",
        "    'B: 4096-float (projection)': {\n",
        "        'train': random_projection(train_features, HDC_DIM),\n",
        "        'test': random_projection(test_features, HDC_DIM),\n",
        "        'dim': HDC_DIM\n",
        "    },\n",
        "    'C: 1536-ternary (quantization)': {\n",
        "        'train': ternary_quantize(train_features),\n",
        "        'test': ternary_quantize(test_features),\n",
        "        'dim': 1536\n",
        "    },\n",
        "    'D: 4096-ternary (full HDC)': {\n",
        "        'train': ternary_quantize(random_projection(train_features, HDC_DIM)),\n",
        "        'test': ternary_quantize(random_projection(test_features, HDC_DIM)),\n",
        "        'dim': HDC_DIM\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"âœ… All configurations prepared:\")\n",
        "for name, cfg in configs.items():\n",
        "    print(f\"   {name}: {cfg['train'].shape}\")"
      ],
      "metadata": {
        "id": "prepare_configs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and Model\n",
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=512, num_classes=3, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(train_features, train_labels, test_features, test_labels,\n",
        "                       input_dim, num_epochs=20, lr=1e-3, verbose=False):\n",
        "    \"\"\"Train MLP and return best accuracy.\"\"\"\n",
        "    \n",
        "    train_dataset = SimpleDataset(train_features, train_labels)\n",
        "    test_dataset = SimpleDataset(test_features, test_labels)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "    \n",
        "    model = MLPClassifier(input_dim=input_dim).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "    \n",
        "    best_acc = 0\n",
        "    history = []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Train\n",
        "        model.train()\n",
        "        for features, labels in train_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(features), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Evaluate\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        with torch.no_grad():\n",
        "            for features, _ in test_loader:\n",
        "                features = features.to(device)\n",
        "                preds = torch.argmax(model(features), dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "        \n",
        "        acc = accuracy_score(test_labels, all_preds)\n",
        "        history.append(acc)\n",
        "        best_acc = max(best_acc, acc)\n",
        "        \n",
        "        if verbose and (epoch + 1) % 5 == 0:\n",
        "            print(f\"  Epoch {epoch+1}: {acc:.1%}\")\n",
        "    \n",
        "    return best_acc, history"
      ],
      "metadata": {
        "id": "train_fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ”¬ RUNNING ABLATION STUDY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, cfg in configs.items():\n",
        "    print(f\"\\nðŸ“Š Testing: {name}\")\n",
        "    \n",
        "    acc, history = train_and_evaluate(\n",
        "        cfg['train'], train_labels,\n",
        "        cfg['test'], test_labels,\n",
        "        input_dim=cfg['dim'],\n",
        "        num_epochs=25,\n",
        "        verbose=True\n",
        "    )\n",
        "    \n",
        "    results[name] = {\n",
        "        'accuracy': acc,\n",
        "        'dim': cfg['dim'],\n",
        "        'history': history\n",
        "    }\n",
        "    \n",
        "    print(f\"   âœ… Best: {acc:.1%}\")"
      ],
      "metadata": {
        "id": "run_ablation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š ABLATION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Extract accuracies\n",
        "acc_A = results['A: 1536-float (no HDC)']['accuracy']\n",
        "acc_B = results['B: 4096-float (projection)']['accuracy']\n",
        "acc_C = results['C: 1536-ternary (quantization)']['accuracy']\n",
        "acc_D = results['D: 4096-ternary (full HDC)']['accuracy']\n",
        "\n",
        "print(f\"\\n{'Config':<35} {'Accuracy':<10} {'vs A (baseline)'}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'A: 1536-float (no HDC)':<35} {acc_A:.1%}      baseline\")\n",
        "print(f\"{'B: 4096-float (projection)':<35} {acc_B:.1%}      {(acc_B - acc_A)*100:+.1f}%\")\n",
        "print(f\"{'C: 1536-ternary (quantization)':<35} {acc_C:.1%}      {(acc_C - acc_A)*100:+.1f}%\")\n",
        "print(f\"{'D: 4096-ternary (full HDC)':<35} {acc_D:.1%}      {(acc_D - acc_A)*100:+.1f}%\")\n",
        "\n",
        "print(f\"\\nðŸ“ˆ LOSS ANALYSIS:\")\n",
        "print(f\"   Projection loss (Aâ†’B): {(acc_A - acc_B)*100:.1f}%\")\n",
        "print(f\"   Quantization loss (Aâ†’C): {(acc_A - acc_C)*100:.1f}%\")\n",
        "print(f\"   Combined loss (Aâ†’D): {(acc_A - acc_D)*100:.1f}%\")\n",
        "print(f\"   Interaction (B+C expected vs D actual): {(acc_B + acc_C - acc_A - acc_D)*100:.1f}%\")"
      ],
      "metadata": {
        "id": "analyze_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine bottleneck\n",
        "proj_loss = acc_A - acc_B\n",
        "quant_loss = acc_A - acc_C\n",
        "total_loss = acc_A - acc_D\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ¯ BOTTLENECK IDENTIFICATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if acc_A < 0.60:\n",
        "    print(f\"\\nâš ï¸ BASELINE (A) IS LOW: {acc_A:.1%}\")\n",
        "    print(f\"   The pair features themselves don't contain enough info!\")\n",
        "    print(f\"   â†’ Need better encoder or richer features\")\n",
        "    bottleneck = \"encoder/features\"\n",
        "elif quant_loss > proj_loss * 2:\n",
        "    print(f\"\\nâš ï¸ QUANTIZATION is the main bottleneck\")\n",
        "    print(f\"   Projection loss: {proj_loss*100:.1f}%\")\n",
        "    print(f\"   Quantization loss: {quant_loss*100:.1f}%\")\n",
        "    print(f\"   â†’ Try softer quantization or higher dimensions\")\n",
        "    bottleneck = \"quantization\"\n",
        "elif proj_loss > quant_loss * 2:\n",
        "    print(f\"\\nâš ï¸ PROJECTION is the main bottleneck\")\n",
        "    print(f\"   Projection loss: {proj_loss*100:.1f}%\")\n",
        "    print(f\"   Quantization loss: {quant_loss*100:.1f}%\")\n",
        "    print(f\"   â†’ Try learned projection or different architecture\")\n",
        "    bottleneck = \"projection\"\n",
        "else:\n",
        "    print(f\"\\nðŸ“Š BOTH contribute roughly equally\")\n",
        "    print(f\"   Projection loss: {proj_loss*100:.1f}%\")\n",
        "    print(f\"   Quantization loss: {quant_loss*100:.1f}%\")\n",
        "    print(f\"   â†’ Need to address both\")\n",
        "    bottleneck = \"both\""
      ],
      "metadata": {
        "id": "identify_bottleneck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bar chart\n",
        "ax = axes[0]\n",
        "names = ['A: Float\\n(baseline)', 'B: Float\\n+Projection', 'C: Ternary\\n(no proj)', 'D: Ternary\\n+Projection']\n",
        "accs = [acc_A, acc_B, acc_C, acc_D]\n",
        "colors = ['green', 'lightblue', 'orange', 'lightcoral']\n",
        "bars = ax.bar(names, accs, color=colors, edgecolor='black')\n",
        "ax.axhline(y=0.33, color='gray', linestyle='--', alpha=0.5, label='Random (33%)')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Ablation Study: Where is Information Lost?')\n",
        "ax.set_ylim(0.3, max(accs) + 0.1)\n",
        "for bar, acc in zip(bars, accs):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "            f'{acc:.1%}', ha='center', fontweight='bold', fontsize=12)\n",
        "ax.legend()\n",
        "\n",
        "# Loss breakdown\n",
        "ax = axes[1]\n",
        "losses = ['Projection\\n(Aâ†’B)', 'Quantization\\n(Aâ†’C)', 'Combined\\n(Aâ†’D)']\n",
        "loss_vals = [proj_loss * 100, quant_loss * 100, total_loss * 100]\n",
        "colors = ['lightblue', 'orange', 'lightcoral']\n",
        "bars = ax.bar(losses, loss_vals, color=colors, edgecolor='black')\n",
        "ax.set_ylabel('Accuracy Loss (%)')\n",
        "ax.set_title('Information Loss by Component')\n",
        "ax.axhline(y=0, color='black', linewidth=0.5)\n",
        "for bar, val in zip(bars, loss_vals):\n",
        "    y_pos = bar.get_height() + 0.5 if val >= 0 else bar.get_height() - 1.5\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, y_pos,\n",
        "            f'{val:.1f}%', ha='center', fontweight='bold', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('ablation_study_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "visualize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning curves\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "for name, data in results.items():\n",
        "    short_name = name.split(':')[0]\n",
        "    ax.plot(data['history'], label=f\"{short_name}: {data['accuracy']:.1%}\", linewidth=2)\n",
        "\n",
        "ax.axhline(y=0.33, color='gray', linestyle='--', alpha=0.5, label='Random')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Test Accuracy')\n",
        "ax.set_title('Learning Curves: Ablation Study')\n",
        "ax.legend(loc='lower right')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('ablation_learning_curves.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "learning_curves"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results\n",
        "output = {\n",
        "    'experiment': 'Phase 1: Ablation Study',\n",
        "    'dataset': 'MNLI',\n",
        "    'train_size': TRAIN_SIZE,\n",
        "    'test_size': TEST_SIZE,\n",
        "    'encoder': 'all-MiniLM-L6-v2',\n",
        "    'hdc_dim': HDC_DIM,\n",
        "    'results': {\n",
        "        'A_float_baseline': acc_A,\n",
        "        'B_float_projected': acc_B,\n",
        "        'C_ternary_only': acc_C,\n",
        "        'D_ternary_projected': acc_D\n",
        "    },\n",
        "    'loss_analysis': {\n",
        "        'projection_loss': float(proj_loss),\n",
        "        'quantization_loss': float(quant_loss),\n",
        "        'combined_loss': float(total_loss)\n",
        "    },\n",
        "    'bottleneck': bottleneck,\n",
        "    'timestamp': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "with open('ablation_study_results.json', 'w') as f:\n",
        "    json.dump(output, f, indent=2)\n",
        "\n",
        "print(\"\\nâœ… Results saved!\")\n",
        "print(json.dumps(output, indent=2))"
      ],
      "metadata": {
        "id": "save_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“‹ NEXT STEPS BASED ON RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if bottleneck == \"encoder/features\":\n",
        "    print(\"\"\"\n",
        "ðŸ”´ ENCODER/FEATURES is the bottleneck!\n",
        "\n",
        "Recommended next experiments:\n",
        "1. Try NLI-tuned encoder (nli-mpnet-base-v2)\n",
        "2. Try two-vector approach (separate HDC for P and H)\n",
        "3. Try richer features (add more interactions)\n",
        "    \"\"\")\n",
        "elif bottleneck == \"quantization\":\n",
        "    print(\"\"\"\n",
        "ðŸŸ  QUANTIZATION is the main bottleneck!\n",
        "\n",
        "Recommended next experiments:\n",
        "1. Try 5-level quantization {-2,-1,0,1,2}\n",
        "2. Try adaptive thresholds\n",
        "3. Try higher dimensions before quantization\n",
        "4. Try tanh before quantization\n",
        "    \"\"\")\n",
        "elif bottleneck == \"projection\":\n",
        "    print(\"\"\"\n",
        "ðŸ”µ PROJECTION is the main bottleneck!\n",
        "\n",
        "Recommended next experiments:\n",
        "1. Try learned projection (train on MNLI)\n",
        "2. Try Project-First-Bind-Later architecture\n",
        "3. Try circular convolution instead of random projection\n",
        "    \"\"\")\n",
        "else:\n",
        "    print(\"\"\"\n",
        "ðŸŸ¡ BOTH projection and quantization contribute!\n",
        "\n",
        "Recommended next experiments:\n",
        "1. Try Project-First-Bind-Later (addresses both)\n",
        "2. Try two-vector approach\n",
        "3. Try NLI encoder + higher dimensions\n",
        "    \"\"\")"
      ],
      "metadata": {
        "id": "next_steps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('ablation_study_results.json')\n",
        "files.download('ablation_study_results.png')\n",
        "files.download('ablation_learning_curves.png')"
      ],
      "metadata": {
        "id": "download"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
