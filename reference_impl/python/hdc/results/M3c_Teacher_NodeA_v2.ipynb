{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üß† M3c‚Ä≤: Semantic Knowledge Transfer ‚Äî Node A (Teacher)\n",
        "\n",
        "**Revolutionary Experiment: Transfer knowledge between DIFFERENT architectures via HDC**\n",
        "\n",
        "**Setup:**\n",
        "- Teacher: DistilBERT (encoder, 66M params)\n",
        "- Student: GPT-2 (decoder, 355M params)\n",
        "- Transfer: Semantic knowledge, NOT weights\n",
        "\n",
        "**Pipeline:**\n",
        "```\n",
        "Teacher (DistilBERT):\n",
        "  1. Measure accuracy BEFORE training\n",
        "  2. Train on sentiment data\n",
        "  3. Measure accuracy AFTER training\n",
        "  4. Extract semantic knowledge (examples + embeddings)\n",
        "  5. Upload to Firebase as \"knowledge packet\"\n",
        "\n",
        "Student (GPT-2) receives and applies knowledge\n",
        "```\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets accelerate\n",
        "!pip install -q firebase-admin\n",
        "!pip install -q sentence-transformers\n",
        "print(\"‚úÖ Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, db\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "NODE_ID = \"node_a_teacher\"\n",
        "print(f\"\\nüéì This is {NODE_ID.upper()} (DistilBERT)\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Firebase credentials\n",
        "FIREBASE_CREDENTIALS = {\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"resonance-m3\",\n",
        "  \"private_key_id\": \"124e2cb57b123eefac08b105c14afa647d3f90e6\",\n",
        "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDMy0nOWX9JaQWk\\nRS3Mz+l5ib8wiwORkJ/rK1ekJoFwaQA3LKM9F1LhAIIRd/cv7X8cfmK5S84g5Yv7\\nrYRMqBVTqItfwC8bET6i6Sf4ooxwwFuIO6qMBUCju3Yqf+ri5gP6GLdKE2cIdGZe\\nSefMIMe8qql609Dnn6BZ7QrKjgEhgd/byYcLuuFoKNTKYSIw++TqmaRBATEOpI4c\\nstCtx42rhp3Rq03ZpNfGDo67Ua0dCzto1NKkScCfUlgLd3v5OrQuU/37a9vgsoEE\\nmcnWxEpjj8Edd4O+KKt0jbduDcMLbKoe42Csrh11VdIRxtJhn0W3dWcb63ZIN1cV\\nBdlR2VsDAgMBAAECggEAG5NsDBsaUU+Q8OkCcnJfOnxagDYtHtazPJQI0xOpmPH/\\n6MNb9QfvowMnKyRU5ovmR8yaN9/bO6wXyKXkC1EUE2sTNADJga2KxPOm7DXcZKT3\\ng5qf1lwxXgVfXfhSL9ylFcdqNtFHWGjEDVeKR371Jj8ctGtSf+iLS6XoLr98VinM\\na7hvEQBy7Y8wUcugrnv08uzvGPDR+MjcLPZ6YIotDgATklbbv2bZf27ZvhZb666J\\nCS/KhqrS9F/6gTxGjxkJ7EGr14apXcLYnyl4WnlnorDOF87U9eCUh/QPSJmNqrbQ\\nP42ZgJkjgclPMnuLHJFtck0LAP6JbJG2KGkn2BMEIQKBgQDss52wA58/73nlVPZX\\nS9jfmFZX79zCqUr8aipeZ9FKbG2yJ/N3MkW6UdeJfPJpxtYyyzKsZy14sLx5Tiii\\nJ3VenhFJm/9CnnyMdGKl4khHpCxQm3whAMVQJmngTAWdK/jSxG7sXvXsBcOYJEr5\\n9nTUqbhx9cQZ5wX0CBpTShKTewKBgQDdfbSWdA6ZCf+ptdvRxtoCqmDKYIAdH1rH\\nbaUvXfJPTzGhO0uNhdGyOe8om67xRu9U8DqOBZD38l5IES5dtxf7Yiqau3KHh/t6\\n73/kJ6UfskhcR6pKkFv1AH5BoxS2BgCChMZO4B87bU3Z5IILvjbbd/7oK8aNqfRo\\nMPhHx16cGQKBgQCzr9raHrXK3GnlzWzAcmStwMBzOzSUVd4F5jZJungoDk3r++YY\\nK4LBYZXE2qRP5lD++EB8nkrnnwtE7y9rgZbZABfRkGnj0dps6YFlunTyZc/6VT6S\\n8znWkYK4ch2k5hebMOGf8KqxxOJp4ctFHHIuarUJVe/LVhSv32LUrZuSdwKBgQCU\\n6BosvEHEKbC0TAtI8UNIX3tLE62N5rKFOPXA7owlPbzEBLU6pCjihYh/6Iqos2Pb\\n2tXC/YME7vDryoE9iAabftfdxv+sloM/lxyIKw8cTCPRxmx6TKtF/9riDd2ysj5N\\ngS5BgPP+Y/He931mn68JxZaeSC/otcYW9jU1LJgyoQKBgDd8YwxP5YkcRnJzIWAe\\n6CMhYOTNxAKnVwSBNctSG4ztzRa+wRSp0G8YNJCmwKKN7xXfJQGLVD8Shq7cfDY2\\nU+0s3jEzbiIqY9W+FQy3dNsfxxR5WK9isG9fWSFfSg4ichXtTGim2eyKxoxlak2+\\nyvvxzpjUtPKMdW2Sp0HkuS13\\n-----END PRIVATE KEY-----\\n\",\n",
        "  \"client_email\": \"firebase-adminsdk-fbsvc@resonance-m3.iam.gserviceaccount.com\",\n",
        "  \"client_id\": \"103650910750904165580\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-fbsvc%40resonance-m3.iam.gserviceaccount.com\",\n",
        "  \"universe_domain\": \"googleapis.com\"\n",
        "}\n",
        "\n",
        "FIREBASE_DATABASE_URL = \"https://resonance-m3-default-rtdb.europe-west1.firebasedatabase.app\"\n",
        "\n",
        "# Initialize Firebase\n",
        "if not firebase_admin._apps:\n",
        "    cred = credentials.Certificate(FIREBASE_CREDENTIALS)\n",
        "    firebase_admin.initialize_app(cred, {\n",
        "        'databaseURL': FIREBASE_DATABASE_URL\n",
        "    })\n",
        "print(\"‚úÖ Firebase initialized\")"
      ],
      "metadata": {
        "id": "firebase"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load Semantic Encoder (model-agnostic)"
      ],
      "metadata": {
        "id": "hdc_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SemanticEncoder:\n",
        "    \"\"\"\n",
        "    Model-agnostic semantic encoder.\n",
        "    Uses SentenceTransformer to create shared semantic space.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        print(\"‚úÖ Semantic encoder loaded (all-MiniLM-L6-v2)\")\n",
        "\n",
        "    def encode(self, texts):\n",
        "        \"\"\"Encode texts to semantic vectors\"\"\"\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "        embeddings = self.encoder.encode(texts, convert_to_numpy=True, show_progress_bar=False)\n",
        "        return embeddings\n",
        "\n",
        "semantic_encoder = SemanticEncoder()"
      ],
      "metadata": {
        "id": "semantic_encoder"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load Teacher Model (DistilBERT)"
      ],
      "metadata": {
        "id": "model_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "\n",
        "print(f\"Loading {MODEL_NAME} for sequence classification...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "\n",
        "print(f\"‚úÖ Teacher model loaded: {MODEL_NAME}\")\n",
        "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Load Dataset"
      ],
      "metadata": {
        "id": "data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading SST-2 dataset...\")\n",
        "dataset = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "# Training data for Teacher\n",
        "TRAIN_SIZE = 2000\n",
        "TEST_SIZE = 500\n",
        "\n",
        "train_texts = dataset['train']['sentence'][:TRAIN_SIZE]\n",
        "train_labels = dataset['train']['label'][:TRAIN_SIZE]\n",
        "\n",
        "# Test data (shared between nodes for evaluation)\n",
        "test_texts = dataset['validation']['sentence'][:TEST_SIZE]\n",
        "test_labels = dataset['validation']['label'][:TEST_SIZE]\n",
        "\n",
        "print(f\"‚úÖ Train: {len(train_texts)}, Test: {len(test_texts)}\")"
      ],
      "metadata": {
        "id": "load_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset class\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.encodings = tokenizer(\n",
        "            list(texts),\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        self.labels = torch.tensor(list(labels))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.encodings['input_ids'][idx],\n",
        "            'attention_mask': self.encodings['attention_mask'][idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
        "test_dataset = SentimentDataset(test_texts, test_labels, tokenizer)\n",
        "\n",
        "print(f\"‚úÖ Datasets created\")"
      ],
      "metadata": {
        "id": "tokenize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Measure BEFORE Training"
      ],
      "metadata": {
        "id": "before_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, texts, tokenizer, batch_size=32):\n",
        "    \"\"\"Get model predictions for texts\"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting\"):\n",
        "        batch_texts = list(texts[i:i+batch_size])\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "    return np.array(predictions)\n",
        "\n",
        "print(\"üìä Measuring predictions BEFORE training...\")\n",
        "predictions_before = get_predictions(model, test_texts, tokenizer)\n",
        "accuracy_before = accuracy_score(test_labels, predictions_before)\n",
        "print(f\"‚úÖ Accuracy BEFORE training: {accuracy_before:.4f}\")"
      ],
      "metadata": {
        "id": "before_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Train Teacher Model"
      ],
      "metadata": {
        "id": "train_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./teacher_output\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=100,\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "print(\"\\nüèãÔ∏è Training teacher model...\")\n",
        "trainer.train()\n",
        "print(\"‚úÖ Training complete!\")"
      ],
      "metadata": {
        "id": "train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Measure AFTER Training"
      ],
      "metadata": {
        "id": "after_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìä Measuring predictions AFTER training...\")\n",
        "predictions_after = get_predictions(model, test_texts, tokenizer)\n",
        "accuracy_after = accuracy_score(test_labels, predictions_after)\n",
        "print(f\"‚úÖ Accuracy AFTER training: {accuracy_after:.4f}\")\n",
        "print(f\"üìà Improvement: {accuracy_after - accuracy_before:.4f} ({(accuracy_after - accuracy_before) * 100:.1f}%)\")"
      ],
      "metadata": {
        "id": "after_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Extract Semantic Knowledge\n",
        "\n",
        "Find examples where the model's prediction CHANGED or is HIGH-CONFIDENCE."
      ],
      "metadata": {
        "id": "extract_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüß† Extracting semantic knowledge...\")\n",
        "\n",
        "# Find examples where prediction changed\n",
        "changed_indices = np.where(predictions_before != predictions_after)[0]\n",
        "print(f\"Found {len(changed_indices)} examples where prediction changed\")\n",
        "\n",
        "# Extract knowledge packet\n",
        "knowledge_packet = {\n",
        "    'teacher_model': MODEL_NAME,\n",
        "    'task': 'sentiment_classification',\n",
        "    'accuracy_before': float(accuracy_before),\n",
        "    'accuracy_after': float(accuracy_after),\n",
        "    'examples': []\n",
        "}\n",
        "\n",
        "# For each changed example, store if prediction is now CORRECT\n",
        "model.eval()\n",
        "for idx in tqdm(changed_indices[:200], desc=\"Extracting changed examples\"):\n",
        "    text = test_texts[idx]\n",
        "    true_label = test_labels[idx]\n",
        "    predicted_label = predictions_after[idx]\n",
        "\n",
        "    # Only include if prediction is now CORRECT\n",
        "    if predicted_label == true_label:\n",
        "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=128).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=1)\n",
        "            confidence = probs[0][predicted_label].item()\n",
        "\n",
        "        embedding = semantic_encoder.encode(text)[0]\n",
        "\n",
        "        knowledge_packet['examples'].append({\n",
        "            'text': text,\n",
        "            'label': int(true_label),\n",
        "            'confidence': float(confidence),\n",
        "            'embedding': embedding.tolist()\n",
        "        })\n",
        "\n",
        "print(f\"‚úÖ Extracted {len(knowledge_packet['examples'])} changed examples\")"
      ],
      "metadata": {
        "id": "extract_knowledge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüéØ Extracting high-confidence training examples...\")\n",
        "\n",
        "confident_examples = []\n",
        "model.eval()\n",
        "\n",
        "for i in tqdm(range(min(500, len(train_texts))), desc=\"Finding confident examples\"):\n",
        "    text = train_texts[i]\n",
        "    true_label = train_labels[i]\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=128).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.softmax(outputs.logits, dim=1)\n",
        "        predicted = torch.argmax(probs, dim=1).item()\n",
        "        confidence = probs[0][predicted].item()\n",
        "\n",
        "    # High confidence AND correct\n",
        "    if confidence > 0.95 and predicted == true_label:\n",
        "        embedding = semantic_encoder.encode(text)[0]\n",
        "        confident_examples.append({\n",
        "            'text': text,\n",
        "            'label': int(true_label),\n",
        "            'confidence': float(confidence),\n",
        "            'embedding': embedding.tolist()\n",
        "        })\n",
        "\n",
        "# Add to knowledge packet (limit to 150)\n",
        "knowledge_packet['confident_examples'] = confident_examples[:150]\n",
        "print(f\"‚úÖ Added {len(knowledge_packet['confident_examples'])} high-confidence examples\")"
      ],
      "metadata": {
        "id": "confident_examples"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Upload Knowledge Packet to Firebase"
      ],
      "metadata": {
        "id": "upload_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüì§ Uploading knowledge packet to Firebase...\")\n",
        "\n",
        "# Add metadata\n",
        "knowledge_packet['timestamp'] = datetime.now().isoformat()\n",
        "knowledge_packet['node'] = NODE_ID\n",
        "knowledge_packet['total_examples'] = len(knowledge_packet['examples']) + len(knowledge_packet.get('confident_examples', []))\n",
        "\n",
        "# Calculate size\n",
        "packet_json = json.dumps(knowledge_packet)\n",
        "packet_size_kb = len(packet_json) / 1024\n",
        "\n",
        "print(f\"Knowledge packet size: {packet_size_kb:.1f} KB\")\n",
        "print(f\"Total examples: {knowledge_packet['total_examples']}\")\n",
        "\n",
        "# Upload\n",
        "ref = db.reference('resonance_m3c/knowledge_packet')\n",
        "ref.set(knowledge_packet)\n",
        "\n",
        "print(f\"\\n‚úÖ Knowledge packet uploaded!\")\n",
        "print(f\"\\nüìã Summary:\")\n",
        "print(f\"   Teacher model: {MODEL_NAME}\")\n",
        "print(f\"   Accuracy: {accuracy_before:.4f} ‚Üí {accuracy_after:.4f} (+{(accuracy_after-accuracy_before)*100:.1f}%)\")\n",
        "print(f\"   Changed examples: {len(knowledge_packet['examples'])}\")\n",
        "print(f\"   Confident examples: {len(knowledge_packet.get('confident_examples', []))}\")\n",
        "print(f\"   Packet size: {packet_size_kb:.1f} KB\")"
      ],
      "metadata": {
        "id": "upload"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Signal ready for Student\n",
        "ref = db.reference('resonance_m3c/status')\n",
        "ref.set({\n",
        "    'teacher_ready': True,\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'teacher_model': MODEL_NAME,\n",
        "    'accuracy_before': float(accuracy_before),\n",
        "    'accuracy_after': float(accuracy_after)\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéì TEACHER NODE COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n‚è≥ Student (GPT-2) can now download and apply knowledge.\")\n",
        "print(f\"\\nRun Node B (Student) notebook now!\")"
      ],
      "metadata": {
        "id": "signal_ready"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results locally\n",
        "results = {\n",
        "    'phase': 'M3c_prime',\n",
        "    'node': NODE_ID,\n",
        "    'experiment': 'Semantic Knowledge Transfer - Teacher',\n",
        "    'model': MODEL_NAME,\n",
        "    'train_samples': TRAIN_SIZE,\n",
        "    'test_samples': TEST_SIZE,\n",
        "    'accuracy_before': float(accuracy_before),\n",
        "    'accuracy_after': float(accuracy_after),\n",
        "    'improvement': float(accuracy_after - accuracy_before),\n",
        "    'changed_examples': len(knowledge_packet['examples']),\n",
        "    'confident_examples': len(knowledge_packet.get('confident_examples', [])),\n",
        "    'total_examples': knowledge_packet['total_examples'],\n",
        "    'packet_size_kb': float(packet_size_kb),\n",
        "    'timestamp': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "with open('m3c_teacher_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Results saved\")\n",
        "print(json.dumps(results, indent=2))"
      ],
      "metadata": {
        "id": "save_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('m3c_teacher_results.json')"
      ],
      "metadata": {
        "id": "download"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
