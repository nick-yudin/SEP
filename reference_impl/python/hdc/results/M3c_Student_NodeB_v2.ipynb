{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“š M3câ€²: Semantic Knowledge Transfer â€” Node B (Student)\n",
        "\n",
        "**Revolutionary Experiment: Learn from DIFFERENT architecture via semantic knowledge**\n",
        "\n",
        "**Setup:**\n",
        "- Teacher: DistilBERT (encoder, 66M params) â€” already trained, 86.6% accuracy\n",
        "- Student: GPT-2 (decoder, 124M params) â€” DIFFERENT architecture!\n",
        "- Transfer: Semantic examples + embeddings, NOT weights\n",
        "\n",
        "**What Student receives:**\n",
        "```\n",
        "Knowledge Packet from Teacher:\n",
        "  - 170 examples where teacher's prediction changed (learned)\n",
        "  - 150 high-confidence examples\n",
        "  - Semantic embeddings for each example\n",
        "  - Total: 320 labeled examples\n",
        "```\n",
        "\n",
        "**Key Question:** Can GPT-2 learn from DistilBERT's knowledge without seeing original training data?\n",
        "\n",
        "---\n",
        "\n",
        "âš ï¸ **Use L4 or A100 GPU** â€” Runtime â†’ Change runtime type â†’ L4"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets accelerate\n",
        "!pip install -q firebase-admin\n",
        "!pip install -q sentence-transformers\n",
        "print(\"âœ… Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, db\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "NODE_ID = \"node_b_student\"\n",
        "print(f\"\\nðŸ“š This is {NODE_ID.upper()} (GPT-2)\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Firebase credentials\n",
        "FIREBASE_CREDENTIALS = {\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"resonance-m3\",\n",
        "  \"private_key_id\": \"124e2cb57b123eefac08b105c14afa647d3f90e6\",\n",
        "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDMy0nOWX9JaQWk\\nRS3Mz+l5ib8wiwORkJ/rK1ekJoFwaQA3LKM9F1LhAIIRd/cv7X8cfmK5S84g5Yv7\\nrYRMqBVTqItfwC8bET6i6Sf4ooxwwFuIO6qMBUCju3Yqf+ri5gP6GLdKE2cIdGZe\\nSefMIMe8qql609Dnn6BZ7QrKjgEhgd/byYcLuuFoKNTKYSIw++TqmaRBATEOpI4c\\nstCtx42rhp3Rq03ZpNfGDo67Ua0dCzto1NKkScCfUlgLd3v5OrQuU/37a9vgsoEE\\nmcnWxEpjj8Edd4O+KKt0jbduDcMLbKoe42Csrh11VdIRxtJhn0W3dWcb63ZIN1cV\\nBdlR2VsDAgMBAAECggEAG5NsDBsaUU+Q8OkCcnJfOnxagDYtHtazPJQI0xOpmPH/\\n6MNb9QfvowMnKyRU5ovmR8yaN9/bO6wXyKXkC1EUE2sTNADJga2KxPOm7DXcZKT3\\ng5qf1lwxXgVfXfhSL9ylFcdqNtFHWGjEDVeKR371Jj8ctGtSf+iLS6XoLr98VinM\\na7hvEQBy7Y8wUcugrnv08uzvGPDR+MjcLPZ6YIotDgATklbbv2bZf27ZvhZb666J\\nCS/KhqrS9F/6gTxGjxkJ7EGr14apXcLYnyl4WnlnorDOF87U9eCUh/QPSJmNqrbQ\\nP42ZgJkjgclPMnuLHJFtck0LAP6JbJG2KGkn2BMEIQKBgQDss52wA58/73nlVPZX\\nS9jfmFZX79zCqUr8aipeZ9FKbG2yJ/N3MkW6UdeJfPJpxtYyyzKsZy14sLx5Tiii\\nJ3VenhFJm/9CnnyMdGKl4khHpCxQm3whAMVQJmngTAWdK/jSxG7sXvXsBcOYJEr5\\n9nTUqbhx9cQZ5wX0CBpTShKTewKBgQDdfbSWdA6ZCf+ptdvRxtoCqmDKYIAdH1rH\\nbaUvXfJPTzGhO0uNhdGyOe8om67xRu9U8DqOBZD38l5IES5dtxf7Yiqau3KHh/t6\\n73/kJ6UfskhcR6pKkFv1AH5BoxS2BgCChMZO4B87bU3Z5IILvjbbd/7oK8aNqfRo\\nMPhHx16cGQKBgQCzr9raHrXK3GnlzWzAcmStwMBzOzSUVd4F5jZJungoDk3r++YY\\nK4LBYZXE2qRP5lD++EB8nkrnnwtE7y9rgZbZABfRkGnj0dps6YFlunTyZc/6VT6S\\n8znWkYK4ch2k5hebMOGf8KqxxOJp4ctFHHIuarUJVe/LVhSv32LUrZuSdwKBgQCU\\n6BosvEHEKbC0TAtI8UNIX3tLE62N5rKFOPXA7owlPbzEBLU6pCjihYh/6Iqos2Pb\\n2tXC/YME7vDryoE9iAabftfdxv+sloM/lxyIKw8cTCPRxmx6TKtF/9riDd2ysj5N\\ngS5BgPP+Y/He931mn68JxZaeSC/otcYW9jU1LJgyoQKBgDd8YwxP5YkcRnJzIWAe\\n6CMhYOTNxAKnVwSBNctSG4ztzRa+wRSp0G8YNJCmwKKN7xXfJQGLVD8Shq7cfDY2\\nU+0s3jEzbiIqY9W+FQy3dNsfxxR5WK9isG9fWSFfSg4ichXtTGim2eyKxoxlak2+\\nyvvxzpjUtPKMdW2Sp0HkuS13\\n-----END PRIVATE KEY-----\\n\",\n",
        "  \"client_email\": \"firebase-adminsdk-fbsvc@resonance-m3.iam.gserviceaccount.com\",\n",
        "  \"client_id\": \"103650910750904165580\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-fbsvc%40resonance-m3.iam.gserviceaccount.com\",\n",
        "  \"universe_domain\": \"googleapis.com\"\n",
        "}\n",
        "\n",
        "FIREBASE_DATABASE_URL = \"https://resonance-m3-default-rtdb.europe-west1.firebasedatabase.app\"\n",
        "\n",
        "# Initialize Firebase\n",
        "if not firebase_admin._apps:\n",
        "    cred = credentials.Certificate(FIREBASE_CREDENTIALS)\n",
        "    firebase_admin.initialize_app(cred, {\n",
        "        'databaseURL': FIREBASE_DATABASE_URL\n",
        "    })\n",
        "print(\"âœ… Firebase initialized\")"
      ],
      "metadata": {
        "id": "firebase"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Check if Teacher is Ready & Download Knowledge"
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ“¡ Checking for Teacher's knowledge packet...\")\n",
        "\n",
        "# Check status\n",
        "ref = db.reference('resonance_m3c/status')\n",
        "status = ref.get()\n",
        "\n",
        "if status and status.get('teacher_ready', False):\n",
        "    print(f\"âœ… Teacher is ready!\")\n",
        "    print(f\"   Model: {status.get('teacher_model', 'unknown')}\")\n",
        "    print(f\"   Accuracy: {status.get('accuracy_before', 0):.1%} â†’ {status.get('accuracy_after', 0):.1%}\")\n",
        "else:\n",
        "    print(\"âš ï¸ Teacher not ready yet. Run Teacher notebook first!\")\n",
        "    raise Exception(\"Teacher not ready\")"
      ],
      "metadata": {
        "id": "check_teacher"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download knowledge packet\n",
        "print(\"\\nðŸ“¥ Downloading knowledge packet...\")\n",
        "ref = db.reference('resonance_m3c/knowledge_packet')\n",
        "knowledge_packet = ref.get()\n",
        "\n",
        "if not knowledge_packet:\n",
        "    raise Exception(\"Knowledge packet not found!\")\n",
        "\n",
        "print(f\"\\nðŸ“‹ Knowledge Packet Contents:\")\n",
        "print(f\"   Teacher model: {knowledge_packet['teacher_model']}\")\n",
        "print(f\"   Teacher accuracy: {knowledge_packet['accuracy_before']:.1%} â†’ {knowledge_packet['accuracy_after']:.1%}\")\n",
        "print(f\"   Changed examples: {len(knowledge_packet.get('examples', []))}\")\n",
        "print(f\"   Confident examples: {len(knowledge_packet.get('confident_examples', []))}\")\n",
        "print(f\"   Total examples: {knowledge_packet.get('total_examples', 0)}\")\n",
        "print(f\"\\nâœ… Knowledge packet downloaded!\")"
      ],
      "metadata": {
        "id": "download_knowledge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load Student Model (GPT-2)\n",
        "\n",
        "This is a DIFFERENT architecture from Teacher (DistilBERT)!"
      ],
      "metadata": {
        "id": "model_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STUDENT_MODEL = \"gpt2\"  # Different architecture from DistilBERT!\n",
        "\n",
        "print(f\"Loading {STUDENT_MODEL} for sequence classification...\")\n",
        "print(f\"(Teacher was: {knowledge_packet['teacher_model']})\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(STUDENT_MODEL)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    STUDENT_MODEL,\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "print(f\"\\nâœ… Student model loaded: {STUDENT_MODEL}\")\n",
        "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"\\nðŸ”„ Cross-architecture transfer: {knowledge_packet['teacher_model']} â†’ {STUDENT_MODEL}\")"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Load Test Dataset (same as Teacher)"
      ],
      "metadata": {
        "id": "data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading SST-2 test dataset...\")\n",
        "dataset = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "TEST_SIZE = 500  # Same as teacher\n",
        "test_texts = dataset['validation']['sentence'][:TEST_SIZE]\n",
        "test_labels = dataset['validation']['label'][:TEST_SIZE]\n",
        "\n",
        "print(f\"âœ… Test set: {len(test_texts)} examples\")"
      ],
      "metadata": {
        "id": "load_test_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Measure Student BEFORE Learning"
      ],
      "metadata": {
        "id": "before_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, texts, tokenizer, batch_size=16):\n",
        "    \"\"\"Get model predictions for texts\"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting\"):\n",
        "        batch_texts = list(texts[i:i+batch_size])\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "    return np.array(predictions)\n",
        "\n",
        "print(\"ðŸ“Š Measuring Student BEFORE learning from Teacher...\")\n",
        "predictions_before = get_predictions(model, test_texts, tokenizer)\n",
        "accuracy_before = accuracy_score(test_labels, predictions_before)\n",
        "print(f\"âœ… Student accuracy BEFORE: {accuracy_before:.4f} ({accuracy_before:.1%})\")"
      ],
      "metadata": {
        "id": "before_learning"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Create Training Data from Knowledge Packet\n",
        "\n",
        "The key: Student learns from Teacher's SEMANTIC EXAMPLES, not weights!"
      ],
      "metadata": {
        "id": "create_data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸ§  Creating training data from Teacher's knowledge...\")\n",
        "\n",
        "# Combine all examples from knowledge packet\n",
        "all_examples = []\n",
        "all_examples.extend(knowledge_packet.get('examples', []))\n",
        "all_examples.extend(knowledge_packet.get('confident_examples', []))\n",
        "\n",
        "# Extract texts and labels\n",
        "knowledge_texts = [ex['text'] for ex in all_examples]\n",
        "knowledge_labels = [ex['label'] for ex in all_examples]\n",
        "\n",
        "print(f\"âœ… Training data from Teacher: {len(knowledge_texts)} examples\")\n",
        "print(f\"\\nðŸ“‹ Sample examples from Teacher:\")\n",
        "for i in range(min(5, len(all_examples))):\n",
        "    ex = all_examples[i]\n",
        "    sentiment = \"ðŸ˜Š positive\" if ex['label'] == 1 else \"ðŸ˜ž negative\"\n",
        "    conf = ex.get('confidence', 0)\n",
        "    print(f\"   [{sentiment}] (conf: {conf:.2f}) \\\"{ex['text'][:50]}...\\\"\")"
      ],
      "metadata": {
        "id": "create_training_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create PyTorch dataset\n",
        "class KnowledgeDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = list(texts)\n",
        "        self.labels = list(labels)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': torch.tensor(self.labels[idx])\n",
        "        }\n",
        "\n",
        "# Create datasets\n",
        "knowledge_dataset = KnowledgeDataset(knowledge_texts, knowledge_labels, tokenizer)\n",
        "test_dataset = KnowledgeDataset(test_texts, test_labels, tokenizer)\n",
        "\n",
        "print(f\"âœ… Datasets created\")\n",
        "print(f\"   Knowledge (from Teacher): {len(knowledge_dataset)} examples\")\n",
        "print(f\"   Test: {len(test_dataset)} examples\")"
      ],
      "metadata": {
        "id": "create_datasets"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Train Student on Teacher's Knowledge\n",
        "\n",
        "ðŸ”¥ **The Magic:** Student learns from SEMANTIC EXAMPLES, not weights!"
      ],
      "metadata": {
        "id": "train_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./student_output\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=3e-5,\n",
        "    warmup_steps=50,\n",
        "    logging_steps=25,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    gradient_accumulation_steps=2\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=knowledge_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“š TRAINING STUDENT ON TEACHER'S KNOWLEDGE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nðŸ”„ Knowledge Transfer:\")\n",
        "print(f\"   FROM: {knowledge_packet['teacher_model']} (Teacher)\")\n",
        "print(f\"   TO:   {STUDENT_MODEL} (Student)\")\n",
        "print(f\"   VIA:  {len(knowledge_texts)} semantic examples\")\n",
        "print(f\"\\n   âš ï¸  NO weight transfer â€” only examples!\")\n",
        "print(f\"\\nðŸ‹ï¸ Training...\")\n",
        "\n",
        "trainer.train()\n",
        "print(\"\\nâœ… Training complete!\")"
      ],
      "metadata": {
        "id": "train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Measure Student AFTER Learning"
      ],
      "metadata": {
        "id": "after_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ“Š Measuring Student AFTER learning from Teacher...\")\n",
        "predictions_after = get_predictions(model, test_texts, tokenizer)\n",
        "accuracy_after = accuracy_score(test_labels, predictions_after)\n",
        "print(f\"âœ… Student accuracy AFTER: {accuracy_after:.4f} ({accuracy_after:.1%})\")"
      ],
      "metadata": {
        "id": "after_learning"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Analyze Results"
      ],
      "metadata": {
        "id": "results_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "student_improvement = accuracy_after - accuracy_before\n",
        "teacher_improvement = knowledge_packet['accuracy_after'] - knowledge_packet['accuracy_before']\n",
        "\n",
        "if teacher_improvement > 0:\n",
        "    transfer_efficiency = (student_improvement / teacher_improvement) * 100\n",
        "else:\n",
        "    transfer_efficiency = 0\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š RESULTS: SEMANTIC KNOWLEDGE TRANSFER\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nðŸŽ“ TEACHER ({knowledge_packet['teacher_model']}):\")\n",
        "print(f\"   Before training: {knowledge_packet['accuracy_before']:.1%}\")\n",
        "print(f\"   After training:  {knowledge_packet['accuracy_after']:.1%}\")\n",
        "print(f\"   Improvement:     +{teacher_improvement:.1%}\")\n",
        "\n",
        "print(f\"\\nðŸ“š STUDENT ({STUDENT_MODEL}):\")\n",
        "print(f\"   Before learning: {accuracy_before:.1%}\")\n",
        "print(f\"   After learning:  {accuracy_after:.1%}\")\n",
        "print(f\"   Improvement:     +{student_improvement:.1%}\")\n",
        "\n",
        "print(f\"\\nðŸ”„ KNOWLEDGE TRANSFER:\")\n",
        "print(f\"   Transfer efficiency: {transfer_efficiency:.1f}%\")\n",
        "print(f\"   (How much of Teacher's improvement transferred to Student)\")"
      ],
      "metadata": {
        "id": "analyze_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine verdict\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“‹ VERDICT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if student_improvement >= 0.20:\n",
        "    verdict = \"SUCCESS\"\n",
        "    emoji = \"ðŸŽ‰\"\n",
        "    message = \"Cross-architecture knowledge transfer WORKS!\"\n",
        "elif student_improvement >= 0.10:\n",
        "    verdict = \"GOOD\"\n",
        "    emoji = \"âœ…\"\n",
        "    message = \"Significant knowledge transferred across architectures.\"\n",
        "elif student_improvement >= 0.05:\n",
        "    verdict = \"PARTIAL\"\n",
        "    emoji = \"âš ï¸\"\n",
        "    message = \"Some knowledge transferred, but limited.\"\n",
        "else:\n",
        "    verdict = \"MINIMAL\"\n",
        "    emoji = \"âŒ\"\n",
        "    message = \"Little to no knowledge transfer detected.\"\n",
        "\n",
        "print(f\"\\n{emoji} {verdict}\")\n",
        "print(f\"\\n{message}\")\n",
        "print(f\"\\nðŸ“ˆ Student improved by {student_improvement:.1%} ({student_improvement*100:.1f} percentage points)\")\n",
        "print(f\"   Using only {len(knowledge_texts)} examples from Teacher\")\n",
        "print(f\"   Across DIFFERENT architectures: {knowledge_packet['teacher_model']} â†’ {STUDENT_MODEL}\")"
      ],
      "metadata": {
        "id": "verdict"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bar chart comparison\n",
        "ax = axes[0]\n",
        "models = ['Teacher\\n(DistilBERT)', 'Student\\n(GPT-2)']\n",
        "before_vals = [knowledge_packet['accuracy_before'], accuracy_before]\n",
        "after_vals = [knowledge_packet['accuracy_after'], accuracy_after]\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, before_vals, width, label='Before', color='lightcoral', edgecolor='darkred')\n",
        "bars2 = ax.bar(x + width/2, after_vals, width, label='After', color='lightgreen', edgecolor='darkgreen')\n",
        "\n",
        "ax.set_ylabel('Accuracy', fontsize=12)\n",
        "ax.set_title('Cross-Architecture Knowledge Transfer', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models, fontsize=11)\n",
        "ax.legend(loc='upper left')\n",
        "ax.set_ylim(0, 1)\n",
        "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Random')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels\n",
        "for bar, val in zip(bars1, before_vals):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, f'{val:.1%}',\n",
        "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "for bar, val in zip(bars2, after_vals):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, f'{val:.1%}',\n",
        "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Flow diagram\n",
        "ax = axes[1]\n",
        "ax.set_xlim(0, 1)\n",
        "ax.set_ylim(0, 1)\n",
        "\n",
        "# Teacher box\n",
        "ax.text(0.2, 0.75, f'Teacher\\n{knowledge_packet[\"teacher_model\"]}', ha='center', va='center', fontsize=12,\n",
        "        bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', edgecolor='blue', linewidth=2))\n",
        "ax.text(0.2, 0.55, f'{knowledge_packet[\"accuracy_after\"]:.1%} accuracy', ha='center', fontsize=10, color='blue')\n",
        "\n",
        "# Student box\n",
        "ax.text(0.8, 0.75, f'Student\\n{STUDENT_MODEL}', ha='center', va='center', fontsize=12,\n",
        "        bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', edgecolor='green', linewidth=2))\n",
        "ax.text(0.8, 0.55, f'{accuracy_after:.1%} accuracy', ha='center', fontsize=10, color='green')\n",
        "\n",
        "# Arrow\n",
        "ax.annotate('', xy=(0.62, 0.75), xytext=(0.38, 0.75),\n",
        "            arrowprops=dict(arrowstyle='->', color='purple', lw=3))\n",
        "ax.text(0.5, 0.85, f'{len(knowledge_texts)} examples', ha='center', fontsize=10, color='purple', fontweight='bold')\n",
        "ax.text(0.5, 0.65, 'Semantic\\nKnowledge', ha='center', fontsize=9, color='purple')\n",
        "\n",
        "# Results\n",
        "result_color = 'green' if student_improvement >= 0.10 else 'orange' if student_improvement >= 0.05 else 'red'\n",
        "ax.text(0.5, 0.25, f'Student Improvement: +{student_improvement:.1%}', ha='center',\n",
        "        fontsize=14, fontweight='bold', color=result_color)\n",
        "ax.text(0.5, 0.12, f'Transfer Efficiency: {transfer_efficiency:.0f}%', ha='center',\n",
        "        fontsize=12, color='gray')\n",
        "\n",
        "ax.text(0.5, 0.02, f'Verdict: {verdict}', ha='center', fontsize=14, fontweight='bold',\n",
        "        bbox=dict(boxstyle='round', facecolor='yellow' if verdict != 'MINIMAL' else 'lightcoral', alpha=0.8))\n",
        "\n",
        "ax.axis('off')\n",
        "ax.set_title('Knowledge Transfer Flow', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('m3c_student_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nâœ… Results visualization saved\")"
      ],
      "metadata": {
        "id": "visualize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results\n",
        "results = {\n",
        "    'phase': 'M3c_prime',\n",
        "    'node': NODE_ID,\n",
        "    'experiment': 'Semantic Knowledge Transfer - Student',\n",
        "    'teacher_model': knowledge_packet['teacher_model'],\n",
        "    'student_model': STUDENT_MODEL,\n",
        "    'knowledge_examples': len(knowledge_texts),\n",
        "    'test_samples': TEST_SIZE,\n",
        "    'teacher_accuracy_before': float(knowledge_packet['accuracy_before']),\n",
        "    'teacher_accuracy_after': float(knowledge_packet['accuracy_after']),\n",
        "    'teacher_improvement': float(teacher_improvement),\n",
        "    'student_accuracy_before': float(accuracy_before),\n",
        "    'student_accuracy_after': float(accuracy_after),\n",
        "    'student_improvement': float(student_improvement),\n",
        "    'transfer_efficiency_pct': float(transfer_efficiency),\n",
        "    'verdict': verdict,\n",
        "    'timestamp': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "# Save locally\n",
        "with open('m3c_student_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "# Upload to Firebase\n",
        "ref = db.reference('resonance_m3c/student_results')\n",
        "ref.set(results)\n",
        "\n",
        "print(\"\\nâœ… Results saved and uploaded to Firebase\")\n",
        "print(\"\\n\" + json.dumps(results, indent=2))"
      ],
      "metadata": {
        "id": "save_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('m3c_student_results.json')\n",
        "files.download('m3c_student_results.png')"
      ],
      "metadata": {
        "id": "download_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ðŸŽ¯ Summary\n",
        "\n",
        "This experiment tested **cross-architecture semantic knowledge transfer**:\n",
        "\n",
        "1. **Teacher (DistilBERT)** learned sentiment classification (49% â†’ 86.6%)\n",
        "2. **Teacher extracted knowledge** as labeled examples + semantic embeddings\n",
        "3. **Student (GPT-2)** learned from these examples WITHOUT seeing original training data\n",
        "4. **Result:** Student improved from random to ???%\n",
        "\n",
        "If successful, this proves that **semantic knowledge can transfer across different model architectures** â€” a key innovation for Resonance Protocol's distributed AI vision."
      ],
      "metadata": {
        "id": "summary"
      }
    }
  ]
}
